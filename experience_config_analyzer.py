#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½“éªŒæ¨¡å¼é…ç½®[x,y,z]å¯¹TileMatchæŒ‡æ ‡å½±å“çš„æ·±åº¦åˆ†æå·¥å…·
å‡çº§ç‰ˆï¼šä½ç½®ç‹¬ç«‹æ•ˆåº”ã€äº¤äº’æ•ˆåº”ã€åŠ¨æ€å½±å“ã€æœºåˆ¶åˆ†æ

ä½œè€…: Claude Code Assistant
å‡çº§æ—¶é—´: 2025-01-27
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler
from scipy import stats
from scipy.stats import pearsonr, spearmanr
import warnings
import os
import sys
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import json

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼ - ä¿®å¤ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
import sys
# æ£€æŸ¥æ“ä½œç³»ç»Ÿå¹¶è®¾ç½®åˆé€‚çš„ä¸­æ–‡å­—ä½“
if sys.platform.startswith('win'):
    # Windowsç³»ç»Ÿå­—ä½“é…ç½®
    plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'KaiTi', 'FangSong']
elif sys.platform.startswith('darwin'):
    # macOSç³»ç»Ÿå­—ä½“é…ç½®
    plt.rcParams['font.sans-serif'] = ['PingFang SC', 'Hiragino Sans GB', 'STHeiti', 'Arial Unicode MS']
else:
    # Linuxç³»ç»Ÿå­—ä½“é…ç½®
    plt.rcParams['font.sans-serif'] = ['Noto Sans CJK SC', 'WenQuanYi Micro Hei', 'DejaVu Sans']

plt.rcParams['axes.unicode_minus'] = False  # æ­£ç¡®æ˜¾ç¤ºè´Ÿå·
plt.rcParams['font.size'] = 10
plt.rcParams['figure.max_open_warning'] = 0  # å…³é—­å›¾è¡¨æ•°é‡è­¦å‘Š
# è®¾ç½®matplotlibåç«¯ä¸ºAggï¼Œé¿å…GUIç›¸å…³é—®é¢˜
import matplotlib
matplotlib.use('Agg')
sns.set_style("whitegrid")
warnings.filterwarnings('ignore')

class ExperienceConfigAnalyzer:
    """ä½“éªŒæ¨¡å¼é…ç½®åˆ†æå™¨ - æ·±åº¦åˆ†æ[x,y,z]ä½ç½®å½±å“æœºåˆ¶"""

    def __init__(self, csv_path: str = None, csv_directory: str = None):
        """åˆå§‹åŒ–åˆ†æå™¨

        Args:
            csv_path: å•ä¸ªCSVæ•°æ®æ–‡ä»¶è·¯å¾„
            csv_directory: CSVæ–‡ä»¶ç›®å½•è·¯å¾„ï¼Œç”¨äºæ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶
        """
        self.csv_path = csv_path
        self.csv_directory = csv_directory or self._find_csv_directory()
        self.data = None
        self.features = None
        self.csv_files = []
        self.target_metrics = [
            'DifficultyScore', 'PeakDockCount', 'PressureValueMean',
            'PressureValueMax', 'PressureValueStdDev', 'FinalDifficulty',
            'InitialMinCost', 'DifficultyPosition'
        ]
        self.results = {}

    def _find_csv_directory(self) -> str:
        """è‡ªåŠ¨æŸ¥æ‰¾CSVæ–‡ä»¶ç›®å½•"""
        current_dir = Path(__file__).parent

        # ä¼˜å…ˆæŸ¥æ‰¾analysis_chartsç›®å½•
        analysis_charts_dir = current_dir / "BattleAnalysisResults" / "analysis_charts"
        if analysis_charts_dir.exists():
            csv_files = list(analysis_charts_dir.glob("*.csv"))
            if csv_files:
                print(f"æ£€æµ‹åˆ°analysis_chartsç›®å½•ï¼ŒåŒ…å«{len(csv_files)}ä¸ªCSVæ–‡ä»¶")
                return str(analysis_charts_dir)

        # æŸ¥æ‰¾BattleAnalysisResultsæ ¹ç›®å½•
        results_dir = current_dir / "BattleAnalysisResults"
        if results_dir.exists():
            csv_files = list(results_dir.glob("*.csv"))
            if csv_files:
                print(f"ğŸ” æ£€æµ‹åˆ°BattleAnalysisResultsç›®å½•ï¼ŒåŒ…å«{len(csv_files)}ä¸ªCSVæ–‡ä»¶")
                return str(results_dir)

        # æŸ¥æ‰¾å½“å‰ç›®å½•
        csv_files = list(current_dir.glob("*.csv"))
        if csv_files:
            print(f"ğŸ” æ£€æµ‹åˆ°å½“å‰ç›®å½•ï¼ŒåŒ…å«{len(csv_files)}ä¸ªCSVæ–‡ä»¶")
            return str(current_dir)

        raise FileNotFoundError("æœªæ‰¾åˆ°åŒ…å«CSVæ–‡ä»¶çš„ç›®å½•ï¼Œè¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨")

    def load_and_preprocess(self) -> 'ExperienceConfigAnalyzer':
        """åŠ è½½æ•°æ®å¹¶è¿›è¡Œé¢„å¤„ç†"""
        print("ğŸ“Š åŠ è½½å’Œé¢„å¤„ç†æ•°æ®...", flush=True)

        if self.csv_path:
            # å•æ–‡ä»¶æ¨¡å¼
            self.data = pd.read_csv(self.csv_path, encoding='utf-8')
            print(f"âœ… å•æ–‡ä»¶æ•°æ®åŠ è½½å®Œæˆ: {len(self.data)}æ¡è®°å½•")
        else:
            # å¤šæ–‡ä»¶æ¨¡å¼ - æ‰¹é‡åŠ è½½
            self._load_multiple_csv_files()

        # è§£æä½“éªŒæ¨¡å¼é…ç½®
        self._parse_experience_config()

        # ç”Ÿæˆç‰¹å¾å·¥ç¨‹
        self._create_features()

        # æ•°æ®æ¸…æ´—
        self._clean_data()

        print(f"ğŸ“ˆ é¢„å¤„ç†å®Œæˆ: {len(self.data)}æ¡æœ‰æ•ˆè®°å½•, {len(self.features.columns)}ä¸ªç‰¹å¾")
        return self

    def _load_multiple_csv_files(self):
        """æ‰¹é‡åŠ è½½å¤šä¸ªCSVæ–‡ä»¶ï¼Œä½¿ç”¨æœ€ç®€å•çš„æ–¹æ¡ˆ"""
        csv_dir = Path(self.csv_directory)
        self.csv_files = sorted(list(csv_dir.glob("*.csv")))

        if not self.csv_files:
            raise FileNotFoundError(f"åœ¨ç›®å½• {csv_dir} ä¸­æœªæ‰¾åˆ°CSVæ–‡ä»¶")

        print(f"ğŸ” å‘ç°{len(self.csv_files)}ä¸ªCSVæ–‡ä»¶ï¼Œå‡†å¤‡æ‰¹é‡åŠ è½½...", flush=True)

        # ç®€å•ç›´æ¥åŠ è½½ï¼Œä¸€ä¸ªæ–‡ä»¶ä¸€ä¸ªæ–‡ä»¶å¤„ç†
        data_list = []
        total_rows = 0

        for i, csv_file in enumerate(self.csv_files):
            print(f"   æ­£åœ¨åŠ è½½ {csv_file.name}... ({i+1}/{len(self.csv_files)})", flush=True)
            sys.stdout.flush()

            try:
                # ç›´æ¥è¯»å–ï¼Œä¸åˆ†å—
                file_data = pd.read_csv(csv_file, encoding='utf-8')
                data_list.append(file_data)
                total_rows += len(file_data)
                print(f"     âœ… {csv_file.name}: {len(file_data)}è¡Œ")

            except Exception as e:
                print(f"     âŒ åŠ è½½{csv_file.name}å¤±è´¥: {str(e)}")
                continue

        if not data_list:
            raise ValueError("æ‰€æœ‰CSVæ–‡ä»¶éƒ½åŠ è½½å¤±è´¥")

        # åˆå¹¶æ‰€æœ‰æ•°æ®
        print("ğŸ”— åˆå¹¶æ‰€æœ‰æ•°æ®...", flush=True)
        self.data = pd.concat(data_list, ignore_index=True)

        print(f"âœ… æ‰¹é‡æ•°æ®åŠ è½½å®Œæˆ: æ€»è®¡{total_rows}æ¡è®°å½•ï¼Œåˆå¹¶å{len(self.data)}æ¡è®°å½•")

    def _parse_experience_config(self):
        """è§£æä½“éªŒæ¨¡å¼é…ç½®[1,2,3]æ ¼å¼ï¼Œä½¿ç”¨æœ€ç®€å•çš„å®ç°"""
        # æ£€æŸ¥ExperienceModeåˆ—æ˜¯å¦å­˜åœ¨
        if 'ExperienceMode' not in self.data.columns:
            print("âš ï¸ æœªæ‰¾åˆ°ExperienceModeåˆ—ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            self.data['pos1'] = 1
            self.data['pos2'] = 2
            self.data['pos3'] = 3
            return

        print("ğŸ”§ è§£æä½“éªŒæ¨¡å¼é…ç½®...", flush=True)

        # ä½¿ç”¨æœ€ç®€å•çš„è§£ææ–¹å¼ï¼Œé¿å…å¤æ‚çš„applyæ“ä½œ
        pos1_list = []
        pos2_list = []
        pos3_list = []

        for config_str in self.data['ExperienceMode']:
            try:
                if pd.isna(config_str):
                    pos1_list.append(1)
                    pos2_list.append(2)
                    pos3_list.append(3)
                    continue

                # ç®€å•å­—ç¬¦ä¸²å¤„ç†
                clean_str = str(config_str).strip('[]"()')
                numbers = [int(x.strip()) for x in clean_str.split(',')]

                if len(numbers) >= 3:
                    pos1_list.append(numbers[0])
                    pos2_list.append(numbers[1])
                    pos3_list.append(numbers[2])
                else:
                    pos1_list.append(1)
                    pos2_list.append(2)
                    pos3_list.append(3)

            except:
                pos1_list.append(1)
                pos2_list.append(2)
                pos3_list.append(3)

        # ç›´æ¥èµ‹å€¼ï¼Œä¸ä½¿ç”¨apply
        self.data['pos1'] = pos1_list
        self.data['pos2'] = pos2_list
        self.data['pos3'] = pos3_list

        # éªŒè¯è§£æç»“æœ
        unique_configs = len(self.data[['pos1', 'pos2', 'pos3']].drop_duplicates())
        print(f"   è§£æå®Œæˆï¼šå‘ç°{unique_configs}ç§ä¸åŒé…ç½®")

    def _create_features(self):
        """åˆ›å»ºç‰¹å¾å·¥ç¨‹"""
        # åŸºç¡€ä½ç½®ç‰¹å¾
        features_df = self.data[['pos1', 'pos2', 'pos3']].copy()

        # ç»Ÿè®¡ç‰¹å¾
        features_df['config_mean'] = (self.data['pos1'] + self.data['pos2'] + self.data['pos3']) / 3
        features_df['config_std'] = np.sqrt(((self.data['pos1'] - features_df['config_mean'])**2 +
                                            (self.data['pos2'] - features_df['config_mean'])**2 +
                                            (self.data['pos3'] - features_df['config_mean'])**2) / 3)
        features_df['config_range'] = np.maximum.reduce([self.data['pos1'], self.data['pos2'], self.data['pos3']]) - \
                                     np.minimum.reduce([self.data['pos1'], self.data['pos2'], self.data['pos3']])
        features_df['config_sum'] = self.data['pos1'] + self.data['pos2'] + self.data['pos3']

        # äº¤äº’ç‰¹å¾
        features_df['pos1_pos2'] = self.data['pos1'] * self.data['pos2']
        features_df['pos1_pos3'] = self.data['pos1'] * self.data['pos3']
        features_df['pos2_pos3'] = self.data['pos2'] * self.data['pos3']
        features_df['pos_product'] = self.data['pos1'] * self.data['pos2'] * self.data['pos3']

        # åºåˆ—æ¨¡å¼ç‰¹å¾
        features_df['is_increasing'] = ((self.data['pos1'] <= self.data['pos2']) &
                                      (self.data['pos2'] <= self.data['pos3'])).astype(int)
        features_df['is_decreasing'] = ((self.data['pos1'] >= self.data['pos2']) &
                                      (self.data['pos2'] >= self.data['pos3'])).astype(int)
        features_df['is_uniform'] = ((self.data['pos1'] == self.data['pos2']) &
                                   (self.data['pos2'] == self.data['pos3'])).astype(int)

        # æå€¼ç‰¹å¾
        features_df['has_extreme_low'] = ((self.data['pos1'] == 1) | (self.data['pos2'] == 1) | (self.data['pos3'] == 1)).astype(int)
        features_df['has_extreme_high'] = ((self.data['pos1'] == 9) | (self.data['pos2'] == 9) | (self.data['pos3'] == 9)).astype(int)

        self.features = features_df

        # å¦‚æœå­˜åœ¨åŒ…å«å¤±è´¥æ•°æ®çš„æ•°æ®é›†ï¼Œä¹Ÿä¸ºå…¶åˆ›å»ºç‰¹å¾
        if hasattr(self, 'data_with_failures') and len(self.data_with_failures) > len(self.data):
            features_with_failures = self.data_with_failures[['pos1', 'pos2', 'pos3']].copy()
            # æ·»åŠ åŸºæœ¬ç‰¹å¾
            features_with_failures['config_mean'] = (self.data_with_failures['pos1'] + self.data_with_failures['pos2'] + self.data_with_failures['pos3']) / 3
            self.features_with_failures = features_with_failures

    def _clean_data(self):
        """æ•°æ®æ¸…æ´—ï¼Œå¢å¼ºè¾¹ç•Œæ¡ä»¶æ£€æŸ¥"""
        initial_count = len(self.data)
        print(f"ğŸ§¹ å¼€å§‹æ•°æ®æ¸…æ´—ï¼Œåˆå§‹è®°å½•æ•°: {initial_count}")

        # ä¿å­˜åŸå§‹ç´¢å¼•ç”¨äºç‰¹å¾æ•°æ®åŒæ­¥
        original_indices = self.data.index.copy()

        # æ£€æŸ¥GameCompletedåˆ—æ˜¯å¦å­˜åœ¨
        if 'GameCompleted' in self.data.columns:
            # å¯¹äºéæˆåŠŸç‡åˆ†æï¼Œç§»é™¤GameCompleted=Falseçš„è®°å½•
            # ä¿ç•™åŸå§‹æ•°æ®ç”¨äºåç»­æˆåŠŸç‡è®¡ç®—
            self.data_with_failures = self.data.copy()  # ä¿å­˜åŒ…å«å¤±è´¥æ¸¸æˆçš„å®Œæ•´æ•°æ®

            completed_mask = (self.data['GameCompleted'] == True) | (self.data['GameCompleted'] == 'True') | (self.data['GameCompleted'] == 1)
            self.data = self.data[completed_mask].copy()
            print(f"   âœ… å®Œæˆæ¸¸æˆè¿‡æ»¤: {len(self.data)}æ¡è®°å½•ç”¨äºä¸»åˆ†æï¼Œ{len(self.data_with_failures)}æ¡è®°å½•ä¿ç•™ç”¨äºæˆåŠŸç‡åˆ†æ")
        else:
            print("   âš ï¸ æœªæ‰¾åˆ°GameCompletedåˆ—ï¼Œè·³è¿‡å®ŒæˆçŠ¶æ€è¿‡æ»¤")
            self.data_with_failures = self.data.copy()  # å¤‡ä»½æ•°æ®

        # ç§»é™¤ç›®æ ‡æŒ‡æ ‡ä¸ºç©ºå€¼çš„è®°å½•
        metrics_found = []
        for metric in self.target_metrics:
            if metric in self.data.columns:
                metrics_found.append(metric)
                before_count = len(self.data)
                self.data = self.data[self.data[metric].notna()].copy()
                if before_count != len(self.data):
                    print(f"   {metric}ç©ºå€¼è¿‡æ»¤: {len(self.data)}æ¡è®°å½•")

        if not metrics_found:
            print("   âš ï¸ æœªæ‰¾åˆ°ä»»ä½•ç›®æ ‡æŒ‡æ ‡åˆ—ï¼Œæ•°æ®å¯èƒ½å­˜åœ¨é—®é¢˜")
        else:
            print(f"   æ‰¾åˆ°{len(metrics_found)}ä¸ªæœ‰æ•ˆæŒ‡æ ‡: {', '.join(metrics_found)}")

        # ç§»é™¤é…ç½®è§£æå¼‚å¸¸çš„è®°å½•
        invalid_config_mask = (
            (self.data['pos1'] < 1) | (self.data['pos1'] > 9) |
            (self.data['pos2'] < 1) | (self.data['pos2'] > 9) |
            (self.data['pos3'] < 1) | (self.data['pos3'] > 9)
        )
        if invalid_config_mask.any():
            invalid_count = invalid_config_mask.sum()
            self.data = self.data[~invalid_config_mask].copy()
            print(f"   é…ç½®å¼‚å¸¸è¿‡æ»¤: ç§»é™¤{invalid_count}æ¡ï¼Œå‰©ä½™{len(self.data)}æ¡è®°å½•")

        # å®‰å…¨çš„ç‰¹å¾æ•°æ®é‡æ–°ç´¢å¼•
        try:
            # æ‰¾åˆ°ç‰¹å¾æ•°æ®å’Œæ¸…æ´—åæ•°æ®çš„äº¤é›†ç´¢å¼•
            valid_indices = self.data.index.intersection(self.features.index)

            if len(valid_indices) == len(self.data):
                # å®Œç¾åŒ¹é…ï¼Œç›´æ¥é‡æ–°ç´¢å¼•
                self.features = self.features.loc[valid_indices].copy()
            else:
                # ä¸å®Œç¾åŒ¹é…ï¼Œé‡æ–°ç”Ÿæˆç‰¹å¾æ•°æ®ä»¥ä¿è¯ä¸€è‡´æ€§
                print(f"   âš ï¸ ç‰¹å¾æ•°æ®ç´¢å¼•ä¸åŒ¹é…ï¼Œé‡æ–°ç”Ÿæˆç‰¹å¾")
                self._create_features()

        except (KeyError, IndexError) as e:
            # ç´¢å¼•ä¸¥é‡ä¸åŒ¹é…ï¼Œé‡æ–°ç”Ÿæˆ
            print(f"   âŒ ç‰¹å¾æ•°æ®ç´¢å¼•é”™è¯¯ï¼Œé‡æ–°ç”Ÿæˆ: {str(e)}")
            self._create_features()

        final_count = len(self.data)
        filtered_ratio = (initial_count - final_count) / initial_count * 100 if initial_count > 0 else 0
        print(f"ğŸ§¹ æ•°æ®æ¸…æ´—å®Œæˆ: {initial_count} -> {final_count}æ¡è®°å½• (è¿‡æ»¤{filtered_ratio:.1f}%)")

        # æ•°æ®è´¨é‡æ£€æŸ¥
        if final_count < initial_count * 0.1:  # å¦‚æœè¿‡æ»¤æ‰è¶…è¿‡90%çš„æ•°æ®
            print(f"âš ï¸ è­¦å‘Š: è¿‡æ»¤æ¯”ä¾‹è¿‡é«˜({filtered_ratio:.1f}%)ï¼Œè¯·æ£€æŸ¥æ•°æ®è´¨é‡")

        if final_count < 100:  # å¦‚æœæœ€ç»ˆæ•°æ®é‡è¿‡å°‘
            print(f"âš ï¸ è­¦å‘Š: æœ‰æ•ˆæ•°æ®é‡è¿‡å°‘({final_count}æ¡)ï¼Œåˆ†æç»“æœå¯èƒ½ä¸å¯é ")

    def correlation_analysis(self) -> Dict:
        """åŸºç¡€ç›¸å…³æ€§åˆ†æ"""
        print("ğŸ”— æ‰§è¡ŒåŸºç¡€ç›¸å…³æ€§åˆ†æ...", flush=True)

        correlations = {}

        # ä½ç½®ç‹¬ç«‹ç›¸å…³æ€§
        position_corrs = {}
        for pos in ['pos1', 'pos2', 'pos3']:
            pos_corrs = {}
            for metric in self.target_metrics:
                if metric in self.data.columns:
                    corr, p_value = pearsonr(self.features[pos], self.data[metric])
                    pos_corrs[metric] = {
                        'correlation': corr,
                        'p_value': p_value,
                        'significant': p_value < 0.05,
                        'effect_size': abs(corr)
                    }
            position_corrs[pos] = pos_corrs

        correlations['position_correlations'] = position_corrs

        # ç‰¹å¾é‡è¦æ€§
        feature_importance = {}
        for metric in self.target_metrics:
            if metric in self.data.columns:
                rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
                rf.fit(self.features, self.data[metric])
                importance_dict = dict(zip(self.features.columns, rf.feature_importances_))
                feature_importance[metric] = dict(sorted(importance_dict.items(),
                                                       key=lambda x: x[1], reverse=True))

        correlations['feature_importance'] = feature_importance
        self.results['correlations'] = correlations
        print("âœ… åŸºç¡€ç›¸å…³æ€§åˆ†æå®Œæˆ")
        return correlations

    def difficulty_position_analysis(self) -> Dict:
        """DifficultyPositionä½ç½®å½±å“åˆ†æ - åˆ†æä¸åŒä½“éªŒé…ç½®åœ¨ä¸åŒä½ç½®å¯¹DifficultyPositionçš„å½±å“"""
        print("ğŸ† æ‰§è¡ŒDifficultyPositionä½ç½®å½±å“åˆ†æ...", flush=True)

        position_effects = {}

        if 'DifficultyPosition' not in self.data.columns:
            print("   âš ï¸ æ— DifficultyPositionåˆ—ï¼Œè·³è¿‡æ­¤åˆ†æ")
            return {}

        # åˆ†ææ¯ä¸ªä½ç½®å¯¹DifficultyPositionçš„å½±å“
        for pos in ['pos1', 'pos2', 'pos3']:
            pos_effects = {}

            # è®¡ç®—æ¯ä¸ªæ•°å€¼çš„DifficultyPositionå¹³å‡å€¼
            value_effects = {}
            for value in range(1, 10):
                subset = self.data[self.features[pos] == value]
                if len(subset) > 5:  # ç¡®ä¿æ ·æœ¬é‡è¶³å¤Ÿ
                    difficulty_pos = subset['DifficultyPosition'].dropna()
                    if len(difficulty_pos) > 0:
                        value_effects[value] = {
                            'mean': difficulty_pos.mean(),
                            'std': difficulty_pos.std(),
                            'median': difficulty_pos.median(),
                            'count': len(difficulty_pos),
                            'min': difficulty_pos.min(),
                            'max': difficulty_pos.max()
                        }

            pos_effects['value_effects'] = value_effects

            # è®¡ç®—ç›¸å…³æ€§
            if len(self.features[pos]) > 0 and len(self.data['DifficultyPosition'].dropna()) > 0:
                corr, p_value = pearsonr(self.features[pos], self.data['DifficultyPosition'].fillna(0))
                pos_effects['correlation'] = {
                    'correlation': corr,
                    'p_value': p_value,
                    'significant': p_value < 0.05
                }

            # æ‰¾å‡ºæœ€ä½³å’Œæœ€å·®é…ç½®ï¼ˆåŸºäº0-1èŒƒå›´ï¼š0=æœ€å‰ï¼Œ0.99=æœ€åï¼Œ1=æ— éš¾ç‚¹ï¼‰
            if value_effects:
                # åˆ†ç¦»ä¸åŒç±»å‹çš„é…ç½®
                no_difficulty_configs = {k: v for k, v in value_effects.items() if abs(v['mean'] - 1.0) < 0.01}  # çº¦ç­‰äº1ï¼Œæ— éš¾ç‚¹
                early_difficulty_configs = {k: v for k, v in value_effects.items() if 0 <= v['mean'] < 0.3}  # å‰æœŸéš¾ç‚¹
                mid_difficulty_configs = {k: v for k, v in value_effects.items() if 0.3 <= v['mean'] < 0.7}  # ä¸­æœŸéš¾ç‚¹
                late_difficulty_configs = {k: v for k, v in value_effects.items() if 0.7 <= v['mean'] < 1.0}  # åæœŸéš¾ç‚¹

                # è¯„ä¼°æœ€ä½³é…ç½®çš„é€»è¾‘
                if mid_difficulty_configs:
                    # ä¸­æœŸéš¾ç‚¹æ˜¯æœ€ç†æƒ³çš„ï¼Œé€‰æ‹©ä¸­æœŸéš¾ç‚¹ä¸­ç›¸å¯¹é åçš„
                    best_value = max(mid_difficulty_configs.items(), key=lambda x: x[1]['mean'])
                    best_description = 'ä¸­æœŸéš¾ç‚¹ï¼ˆç†æƒ³èŠ‚å¥ï¼‰'
                elif late_difficulty_configs:
                    # åæœŸéš¾ç‚¹æ¬¡ä¹‹ï¼Œé€‰æ‹©é€‚ä¸­çš„åæœŸéš¾ç‚¹
                    best_value = min(late_difficulty_configs.items(), key=lambda x: x[1]['mean'])
                    best_description = 'åæœŸéš¾ç‚¹ï¼ˆæ¸è¿›å¼æŒ‘æˆ˜ï¼‰'
                elif no_difficulty_configs:
                    # æ— æ˜æ˜¾éš¾ç‚¹ä¹Ÿå¯ä»¥æ¥å—
                    best_value = list(no_difficulty_configs.items())[0]
                    best_description = 'æ— æ˜æ˜¾éš¾ç‚¹ï¼ˆå¹³å‡ä½“éªŒï¼‰'
                elif early_difficulty_configs:
                    # å¦‚æœåªæœ‰å‰æœŸéš¾ç‚¹ï¼Œé€‰æ‹©ç›¸å¯¹é åçš„
                    best_value = max(early_difficulty_configs.items(), key=lambda x: x[1]['mean'])
                    best_description = 'å‰æœŸéš¾ç‚¹ï¼ˆç›¸å¯¹è¾ƒæ™šï¼‰'
                else:
                    # å…œåº•
                    best_value = max(value_effects.items(), key=lambda x: x[1]['mean'])
                    best_description = 'ç›¸å¯¹æœ€ä½³'

                # è¯„ä¼°æœ€å·®é…ç½®çš„é€»è¾‘
                if early_difficulty_configs:
                    # å‰æœŸéš¾ç‚¹æ˜¯æœ€å·®çš„ï¼Œé€‰æ‹©æœ€æ—©çš„
                    worst_value = min(early_difficulty_configs.items(), key=lambda x: x[1]['mean'])
                    worst_description = 'å‰æœŸéš¾ç‚¹ï¼ˆå¼€å±€æŒ«è´¥ï¼‰'
                elif value_effects:
                    # å¦‚æœæ²¡æœ‰å‰æœŸéš¾ç‚¹ï¼Œé€‰æ‹©æœ€ä¸ç†æƒ³çš„
                    worst_value = min(value_effects.items(), key=lambda x: x[1]['mean'])
                    worst_description = 'ç›¸å¯¹æœ€å·®'
                else:
                    worst_value = best_value
                    worst_description = 'ç›¸å¯¹æœ€å·®'

                pos_effects['best_config'] = {
                    'value': best_value[0],
                    'mean_difficulty_position': best_value[1]['mean'],
                    'sample_count': best_value[1]['count'],
                    'description': best_description
                }

                pos_effects['worst_config'] = {
                    'value': worst_value[0],
                    'mean_difficulty_position': worst_value[1]['mean'],
                    'sample_count': worst_value[1]['count'],
                    'description': worst_description
                }

                # æ·»åŠ å„ç±»é…ç½®çš„ç»Ÿè®¡
                config_categories = {
                    'no_difficulty': (no_difficulty_configs, 'æ— æ˜æ˜¾éš¾ç‚¹'),
                    'early_difficulty': (early_difficulty_configs, 'å‰æœŸéš¾ç‚¹'),
                    'mid_difficulty': (mid_difficulty_configs, 'ä¸­æœŸéš¾ç‚¹'),
                    'late_difficulty': (late_difficulty_configs, 'åæœŸéš¾ç‚¹')
                }

                for category_name, (configs, description) in config_categories.items():
                    if configs:
                        pos_effects[f'{category_name}_configs'] = {
                            'count': len(configs),
                            'values': list(configs.keys()),
                            'description': description,
                            'avg_position': sum(v['mean'] for v in configs.values()) / len(configs)
                        }

            position_effects[pos] = pos_effects

        # äº¤äº’æ•ˆåº”åˆ†æ
        interaction_effects = {}
        for pos_pair in [('pos1', 'pos2'), ('pos1', 'pos3'), ('pos2', 'pos3')]:
            pair_key = f"{pos_pair[0]}Ã—{pos_pair[1]}"

            # è®¡ç®—äº¤äº’é¡¹å¯¹DifficultyPositionçš„å½±å“
            interaction_feature = self.features[pos_pair[0]] * self.features[pos_pair[1]]

            # åŸºç¡€æ¨¡å‹ vs äº¤äº’æ¨¡å‹
            X_base = self.features[[pos_pair[0], pos_pair[1]]]
            X_inter = X_base.copy()
            X_inter['interaction'] = interaction_feature

            y_valid = self.data['DifficultyPosition'].dropna()
            X_base_valid = X_base.loc[y_valid.index]
            X_inter_valid = X_inter.loc[y_valid.index]

            if len(y_valid) > 10:
                try:
                    rf_base = RandomForestRegressor(n_estimators=50, random_state=42)
                    rf_base.fit(X_base_valid, y_valid)
                    r2_base = rf_base.score(X_base_valid, y_valid)

                    rf_inter = RandomForestRegressor(n_estimators=50, random_state=42)
                    rf_inter.fit(X_inter_valid, y_valid)
                    r2_inter = rf_inter.score(X_inter_valid, y_valid)

                    interaction_effects[pair_key] = {
                        'r2_base': r2_base,
                        'r2_interaction': r2_inter,
                        'interaction_gain': r2_inter - r2_base,
                        'sample_count': len(y_valid)
                    }
                except Exception as e:
                    print(f"   âš ï¸ {pair_key}äº¤äº’åˆ†æå¤±è´¥: {str(e)}")

        position_effects['interaction_effects'] = interaction_effects

        self.results['difficulty_position_effects'] = position_effects
        print("âœ… DifficultyPositionä½ç½®å½±å“åˆ†æå®Œæˆ")
        return position_effects

    def position_independent_analysis(self) -> Dict:
        """ä½ç½®ç‹¬ç«‹å½±å“åˆ†æ - æ§åˆ¶å…¶ä»–å˜é‡åˆ†æå•ä¸ªä½ç½®çš„çº¯å‡€æ•ˆåº”"""
        print("ğŸ¯ æ‰§è¡Œä½ç½®ç‹¬ç«‹å½±å“åˆ†æ...", flush=True)

        independent_effects = {}

        for pos in ['pos1', 'pos2', 'pos3']:
            pos_effects = {}

            for metric in ['DifficultyScore', 'PeakDockCount', 'PressureValueMean']:
                if metric in self.data.columns:
                    # è®¡ç®—è¾¹é™…æ•ˆåº”ï¼šposæ¯å˜åŒ–1å•ä½å¯¹metricçš„å½±å“
                    marginal_effects = []

                    # åˆ†æä¸åŒæ•°å€¼åŒºé—´çš„æ•ˆåº”
                    for value in range(1, 10):
                        subset = self.data[self.features[pos] == value]
                        if len(subset) > 5:  # ç¡®ä¿æ ·æœ¬é‡è¶³å¤Ÿ
                            avg_metric = subset[metric].mean()
                            marginal_effects.append((value, avg_metric))

                    if len(marginal_effects) > 2:
                        # è®¡ç®—è¾¹é™…é€’å¢æ•ˆåº”
                        marginal_diffs = []
                        for i in range(1, len(marginal_effects)):
                            diff = marginal_effects[i][1] - marginal_effects[i-1][1]
                            marginal_diffs.append(diff)

                        pos_effects[metric] = {
                            'marginal_effects': marginal_effects,
                            'avg_marginal_diff': np.mean(marginal_diffs),
                            'marginal_volatility': np.std(marginal_diffs)
                        }

            independent_effects[pos] = pos_effects

        self.results['independent_effects'] = independent_effects
        print("âœ… ä½ç½®ç‹¬ç«‹å½±å“åˆ†æå®Œæˆ")
        return independent_effects

    def interaction_analysis(self) -> Dict:
        """ä½ç½®äº¤äº’æ•ˆåº”åˆ†æ - åˆ†æä½ç½®é—´ç›¸äº’ä½œç”¨"""
        print("ğŸ”„ æ‰§è¡Œä½ç½®äº¤äº’æ•ˆåº”åˆ†æ...", flush=True)

        interaction_effects = {}

        # åŒä½ç½®äº¤äº’åˆ†æ
        for pos_pair in [('pos1', 'pos2'), ('pos1', 'pos3'), ('pos2', 'pos3')]:
            pair_key = f"{pos_pair[0]}Ã—{pos_pair[1]}"
            pair_effects = {}

            for metric in ['DifficultyScore', 'PeakDockCount']:
                if metric in self.data.columns:
                    # åˆ›å»ºäº¤äº’ç‰¹å¾
                    interaction_feature = self.features[pos_pair[0]] * self.features[pos_pair[1]]

                    # æ¯”è¾ƒæœ‰äº¤äº’é¡¹vsæ— äº¤äº’é¡¹çš„æ¨¡å‹æ€§èƒ½
                    X_base = self.features[[pos_pair[0], pos_pair[1]]]
                    X_inter = X_base.copy()
                    X_inter['interaction'] = interaction_feature

                    # åŸºç¡€æ¨¡å‹
                    rf_base = RandomForestRegressor(n_estimators=50, random_state=42)
                    rf_base.fit(X_base, self.data[metric])
                    r2_base = rf_base.score(X_base, self.data[metric])

                    # äº¤äº’æ¨¡å‹
                    rf_inter = RandomForestRegressor(n_estimators=50, random_state=42)
                    rf_inter.fit(X_inter, self.data[metric])
                    r2_inter = rf_inter.score(X_inter, self.data[metric])

                    pair_effects[metric] = {
                        'r2_base': r2_base,
                        'r2_interaction': r2_inter,
                        'interaction_gain': r2_inter - r2_base,
                        'interaction_strength': abs(r2_inter - r2_base)
                    }

            interaction_effects[pair_key] = pair_effects

        self.results['interaction_effects'] = interaction_effects
        print("âœ… ä½ç½®äº¤äº’æ•ˆåº”åˆ†æå®Œæˆ")
        return interaction_effects

    def dynamic_impact_analysis(self) -> Dict:
        """åŠ¨æ€å½±å“åˆ†æ - åˆ†æä½ç½®åœ¨ä¸åŒæ¸¸æˆé˜¶æ®µçš„å·®å¼‚åŒ–å½±å“"""
        print("â±ï¸ æ‰§è¡ŒåŠ¨æ€å½±å“åˆ†æ...", flush=True)

        dynamic_effects = {}

        # è§£æDockAfterTrioMatchåºåˆ—æ•°æ®
        dock_sequences = []
        for dock_str in self.data['DockAfterTrioMatch'].fillna(''):
            if dock_str:
                try:
                    dock_values = [int(x) for x in str(dock_str).split(',')]
                    dock_sequences.append(dock_values)
                except:
                    dock_sequences.append([])
            else:
                dock_sequences.append([])

        # åˆ†æå„ä½ç½®å¯¹ä¸åŒæ¸¸æˆé˜¶æ®µçš„å½±å“
        for pos in ['pos1', 'pos2', 'pos3']:
            pos_dynamic = {}

            # åˆ†æå¯¹æ¸¸æˆå‰æœŸã€ä¸­æœŸã€åæœŸçš„å·®å¼‚åŒ–å½±å“
            stage_effects = {'early': [], 'middle': [], 'late': []}

            for i, dock_seq in enumerate(dock_sequences):
                if len(dock_seq) >= 6:  # ç¡®ä¿åºåˆ—è¶³å¤Ÿé•¿
                    seq_len = len(dock_seq)
                    early_avg = np.mean(dock_seq[:seq_len//3])
                    middle_avg = np.mean(dock_seq[seq_len//3:2*seq_len//3])
                    late_avg = np.mean(dock_seq[2*seq_len//3:])

                    pos_value = self.features.iloc[i][pos]
                    stage_effects['early'].append((pos_value, early_avg))
                    stage_effects['middle'].append((pos_value, middle_avg))
                    stage_effects['late'].append((pos_value, late_avg))

            # è®¡ç®—å„é˜¶æ®µçš„ç›¸å…³æ€§
            for stage, values in stage_effects.items():
                if len(values) > 10:
                    pos_vals, dock_vals = zip(*values)
                    corr, _ = pearsonr(pos_vals, dock_vals)
                    pos_dynamic[f'{stage}_correlation'] = corr

            dynamic_effects[pos] = pos_dynamic

        self.results['dynamic_effects'] = dynamic_effects
        print("âœ… åŠ¨æ€å½±å“åˆ†æå®Œæˆ")
        return dynamic_effects

    def mechanism_analysis(self) -> Dict:
        """å½±å“æœºåˆ¶åˆ†æ - åˆ†æä½ç½®å½±å“æŒ‡æ ‡çš„ä¸­ä»‹è·¯å¾„"""
        print("ğŸ” æ‰§è¡Œå½±å“æœºåˆ¶åˆ†æ...", flush=True)

        mechanism_effects = {}

        # å¯¹äºæ¯ä¸ªä½ç½®ï¼Œåˆ†æå…¶å¯¹DifficultyScoreçš„ä¸­ä»‹è·¯å¾„
        for pos in ['pos1', 'pos2', 'pos3']:
            pos_mechanism = {}

            # ç›´æ¥æ•ˆåº”ï¼špos -> DifficultyScore
            if 'DifficultyScore' in self.data.columns:
                direct_corr, _ = pearsonr(self.features[pos], self.data['DifficultyScore'])
                pos_mechanism['direct_effect'] = direct_corr

                # ä¸­ä»‹æ•ˆåº”åˆ†æï¼špos -> ä¸­ä»‹å˜é‡ -> DifficultyScore
                mediators = ['PressureValueMean', 'PeakDockCount', 'PressureValueMax']
                mediation_effects = {}

                for mediator in mediators:
                    if mediator in self.data.columns:
                        # pos -> mediator
                        corr_pm, _ = pearsonr(self.features[pos], self.data[mediator])
                        # mediator -> DifficultyScore
                        corr_md, _ = pearsonr(self.data[mediator], self.data['DifficultyScore'])
                        # ä¸­ä»‹æ•ˆåº”å¼ºåº¦ = ä¸¤ä¸ªç›¸å…³ç³»æ•°çš„ä¹˜ç§¯
                        mediation_strength = corr_pm * corr_md

                        mediation_effects[mediator] = {
                            'pos_to_mediator': corr_pm,
                            'mediator_to_target': corr_md,
                            'mediation_strength': mediation_strength
                        }

                pos_mechanism['mediation_effects'] = mediation_effects

                # æ‰¾å‡ºæœ€å¼ºçš„ä¸­ä»‹è·¯å¾„
                if mediation_effects:
                    strongest_mediator = max(mediation_effects.items(),
                                           key=lambda x: abs(x[1]['mediation_strength']))
                    pos_mechanism['strongest_mediation_path'] = {
                        'mediator': strongest_mediator[0],
                        'strength': strongest_mediator[1]['mediation_strength']
                    }

            mechanism_effects[pos] = pos_mechanism

        self.results['mechanism_effects'] = mechanism_effects
        print("âœ… å½±å“æœºåˆ¶åˆ†æå®Œæˆ")
        return mechanism_effects

    def value_specific_analysis(self, target_value: int = None) -> Dict:
        """å•ä¸€æ•°å€¼æ·±åº¦åˆ†æ - åˆ†æç‰¹å®šæ•°å€¼(å¦‚x=5)åœ¨ä¸åŒä½ç½®çš„å®Œæ•´å½±å“"""
        print(f"ğŸ¯ æ‰§è¡Œå•ä¸€æ•°å€¼æ·±åº¦åˆ†æ (ç›®æ ‡æ•°å€¼: {target_value or 'å…¨éƒ¨'})...")

        value_effects = {}
        values_to_analyze = [target_value] if target_value else range(1, 10)

        for value in values_to_analyze:
            value_key = f"value_{value}"
            value_data = {}

            for pos in ['pos1', 'pos2', 'pos3']:
                pos_data = {}

                # ç­›é€‰è¯¥æ•°å€¼åœ¨è¯¥ä½ç½®çš„æ•°æ®
                mask = self.features[pos] == value
                subset = self.data[mask]

                if len(subset) < 10:  # æ ·æœ¬é‡å¤ªå°‘è·³è¿‡
                    continue

                # DifficultyScoreå½±å“åˆ†æ
                if 'DifficultyScore' in subset.columns:
                    difficulty_stats = {
                        'mean': subset['DifficultyScore'].mean(),
                        'std': subset['DifficultyScore'].std(),
                        'median': subset['DifficultyScore'].median(),
                        'min': subset['DifficultyScore'].min(),
                        'max': subset['DifficultyScore'].max(),
                        'count': len(subset)
                    }
                    pos_data['difficulty_impact'] = difficulty_stats

                # èƒœç‡åˆ†æ - ä½¿ç”¨åŒ…å«å¤±è´¥æ¸¸æˆçš„å®Œæ•´æ•°æ®
                if 'GameCompleted' in self.data_with_failures.columns:
                    # ä»å®Œæ•´æ•°æ®ä¸­ç­›é€‰å½“å‰é…ç½®çš„å­é›†
                    # å®‰å…¨çš„ç´¢å¼•æ–¹å¼å¤„ç†åŒ…å«å¤±è´¥æ•°æ®çš„å®Œæ•´æ•°æ®é›†
                    if hasattr(self, 'data_with_failures'):
                        if hasattr(self, 'features_with_failures'):
                            # ä½¿ç”¨åŒ…å«å¤±è´¥æ•°æ®çš„ç‰¹å¾
                            full_subset = self.data_with_failures[self.features_with_failures[pos] == value]
                        else:
                            # ç›´æ¥ä»åŸå§‹æ•°æ®ä¸­è§£æé…ç½®è¿›è¡Œç­›é€‰
                            def get_pos_value(exp_mode_str):
                                try:
                                    clean_str = str(exp_mode_str).strip('[]"()')
                                    numbers = [int(x.strip()) for x in clean_str.split(',')]
                                    if len(numbers) >= 3:
                                        pos_map = {'pos1': numbers[0], 'pos2': numbers[1], 'pos3': numbers[2]}
                                        return pos_map.get(pos, 0)
                                    return 0
                                except:
                                    return 0

                            exp_mode_filter = self.data_with_failures['ExperienceMode'].astype(str).apply(
                                lambda x: get_pos_value(x) == value
                            )
                            full_subset = self.data_with_failures[exp_mode_filter]
                    else:
                        full_subset = subset
                    if len(full_subset) > 0:
                        # æ­£ç¡®å¤„ç†GameCompletedåˆ—çš„ä¸åŒæ ¼å¼
                        completed_mask = (full_subset['GameCompleted'] == True) | (full_subset['GameCompleted'] == 'True') | (full_subset['GameCompleted'] == 1)
                        win_rate = completed_mask.mean()
                        pos_data['win_rate'] = {
                            'success_rate': win_rate,
                            'failure_rate': 1 - win_rate,
                            'total_games': len(full_subset)
                        }

                # DockAfterTrioMatchåºåˆ—åˆ†æ
                if 'DockAfterTrioMatch' in subset.columns:
                    dock_analysis = self._analyze_dock_sequences(subset['DockAfterTrioMatch'])
                    pos_data['dock_impact'] = dock_analysis

                # PressureValuesåˆ†æ
                pressure_analysis = {}
                for pressure_col in ['PressureValueMean', 'PressureValueMax', 'PressureValueStdDev']:
                    if pressure_col in subset.columns:
                        pressure_analysis[pressure_col] = {
                            'mean': subset[pressure_col].mean(),
                            'std': subset[pressure_col].std(),
                            'median': subset[pressure_col].median()
                        }
                pos_data['pressure_impact'] = pressure_analysis

                value_data[pos] = pos_data

            value_effects[value_key] = value_data

        self.results['value_specific_effects'] = value_effects
        print("âœ… å•ä¸€æ•°å€¼æ·±åº¦åˆ†æå®Œæˆ")
        return value_effects

    def _analyze_dock_sequences(self, dock_series) -> Dict:
        """åˆ†æDockAfterTrioMatchåºåˆ—çš„è¾…åŠ©æ–¹æ³•"""
        sequences = []
        for dock_str in dock_series.fillna(''):
            if dock_str:
                try:
                    dock_values = [int(x) for x in str(dock_str).split(',')]
                    sequences.append(dock_values)
                except:
                    continue

        if not sequences:
            return {}

        # è®¡ç®—åºåˆ—ç»Ÿè®¡
        seq_lengths = [len(seq) for seq in sequences]

        # åˆ†æä¸åŒé˜¶æ®µçš„å¹³å‡Dockå€¼
        early_vals, middle_vals, late_vals = [], [], []
        for seq in sequences:
            if len(seq) >= 6:
                third = len(seq) // 3
                early_vals.extend(seq[:third])
                middle_vals.extend(seq[third:2*third])
                late_vals.extend(seq[2*third:])

        return {
            'total_sequences': len(sequences),
            'phase_analysis': {
                'early_phase': {'mean': np.mean(early_vals) if early_vals else 0, 'count': len(early_vals)},
                'middle_phase': {'mean': np.mean(middle_vals) if middle_vals else 0, 'count': len(middle_vals)},
                'late_phase': {'mean': np.mean(late_vals) if late_vals else 0, 'count': len(late_vals)}
            }
        }

    def gradient_effect_analysis(self) -> Dict:
        """æ•°å€¼æ¢¯åº¦æ•ˆåº”åˆ†æ - åˆ†æ1-9æ•°å€¼çš„è¿ç»­å½±å“å˜åŒ–"""
        print("ğŸ“ˆ æ‰§è¡Œæ•°å€¼æ¢¯åº¦æ•ˆåº”åˆ†æ...")

        gradient_effects = {}

        for pos in ['pos1', 'pos2', 'pos3']:
            pos_gradients = {}

            # ä¸»è¦æŒ‡æ ‡çš„æ¢¯åº¦åˆ†æ
            for metric in ['DifficultyScore', 'PeakDockCount', 'PressureValueMean']:
                if metric in self.data.columns:

                    # è®¡ç®—æ¯ä¸ªæ•°å€¼çš„å¹³å‡æŒ‡æ ‡å€¼
                    value_means = []
                    value_counts = []

                    for value in range(1, 10):
                        subset = self.data[self.features[pos] == value]
                        if len(subset) > 0:
                            value_means.append(subset[metric].mean())
                            value_counts.append(len(subset))
                        else:
                            value_means.append(np.nan)
                            value_counts.append(0)

                    # è®¡ç®—æ¢¯åº¦(ç›¸é‚»æ•°å€¼é—´çš„å·®å€¼)
                    gradients = []
                    for i in range(1, len(value_means)):
                        if not (np.isnan(value_means[i]) or np.isnan(value_means[i-1])):
                            gradient = value_means[i] - value_means[i-1]
                            gradients.append(gradient)
                        else:
                            gradients.append(np.nan)

                    # è¯†åˆ«æœ€å¤§æ¢¯åº¦å˜åŒ–ç‚¹(ä¸´ç•Œç‚¹)
                    abs_gradients = [abs(g) for g in gradients if not np.isnan(g)]
                    if abs_gradients:
                        max_gradient_idx = gradients.index(max(gradients, key=abs))
                        critical_point = max_gradient_idx + 2  # +2å› ä¸ºæ¢¯åº¦æ˜¯å·®å€¼,å¯¹åº”åä¸€ä¸ªæ•°å€¼
                    else:
                        critical_point = None

                    pos_gradients[metric] = {
                        'value_means': value_means,
                        'gradients': gradients,
                        'critical_point': critical_point,
                        'max_gradient': max(abs_gradients) if abs_gradients else 0,
                        'avg_gradient': np.mean([g for g in gradients if not np.isnan(g)]) if gradients else 0
                    }

            gradient_effects[pos] = pos_gradients

        self.results['gradient_effects'] = gradient_effects
        print("âœ… æ•°å€¼æ¢¯åº¦æ•ˆåº”åˆ†æå®Œæˆ")
        return gradient_effects

    def dock_sequence_deep_analysis(self) -> Dict:
        """DockAfterTrioMatchåºåˆ—æ·±åº¦åˆ†æ"""
        print("ğŸš¢ æ‰§è¡ŒDockåºåˆ—æ·±åº¦åˆ†æ...")

        dock_deep_analysis = {}

        # è§£ææ‰€æœ‰åºåˆ—æ•°æ® - ä½¿ç”¨åŒ…å«å¤±è´¥æ¸¸æˆçš„å®Œæ•´æ•°æ®è¿›è¡ŒæˆåŠŸç‡è®¡ç®—
        data_for_analysis = self.data_with_failures if hasattr(self, 'data_with_failures') else self.data
        all_sequences = []
        sequence_metadata = []

        for idx, row in data_for_analysis.iterrows():
            dock_str = row.get('DockAfterTrioMatch', '')
            if dock_str and str(dock_str) != 'nan':
                try:
                    dock_values = [int(x) for x in str(dock_str).split(',')]
                    all_sequences.append(dock_values)

                    # éœ€è¦ä»ç‰¹å¾æ•°æ®ä¸­è·å–posé…ç½®ï¼ˆå¦‚æœç´¢å¼•å¯¹åº”çš„è¯ï¼‰
                    if idx in self.features.index:
                        pos_config = {
                            'pos1': self.features.loc[idx, 'pos1'],
                            'pos2': self.features.loc[idx, 'pos2'],
                            'pos3': self.features.loc[idx, 'pos3']
                        }
                    else:
                        # é‡æ–°è§£æé…ç½®ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
                        exp_mode = row.get('ExperienceMode', '[1,2,3]')
                        try:
                            clean_str = str(exp_mode).strip('[]"()')
                            numbers = [int(x.strip()) for x in clean_str.split(',')]
                            if len(numbers) >= 3:
                                pos_config = {'pos1': numbers[0], 'pos2': numbers[1], 'pos3': numbers[2]}
                            else:
                                pos_config = {'pos1': 1, 'pos2': 2, 'pos3': 3}
                        except:
                            pos_config = {'pos1': 1, 'pos2': 2, 'pos3': 3}

                    sequence_metadata.append({
                        **pos_config,
                        'difficulty': row.get('DifficultyScore', 0),
                        'completed': row.get('GameCompleted', False)
                    })
                except:
                    continue

        if not all_sequences:
            return {}

        # æŒ‰ä½ç½®åˆ†ç»„åˆ†æ
        for pos in ['pos1', 'pos2', 'pos3']:
            pos_analysis = {}

            for value in range(1, 10):
                value_sequences = []
                value_metadata = []

                for i, meta in enumerate(sequence_metadata):
                    if meta[pos] == value:
                        value_sequences.append(all_sequences[i])
                        value_metadata.append(meta)

                if len(value_sequences) < 5:  # æ ·æœ¬é‡å¤ªå°‘
                    continue

                # åºåˆ—é•¿åº¦åˆ†æ
                lengths = [len(seq) for seq in value_sequences]

                # åºåˆ—æ¨¡å¼åˆ†æ
                patterns = self._identify_dock_patterns(value_sequences)

                # å±é™©æ—¶åˆ»åˆ†æ(Dock>=6çš„æ—¶åˆ»)
                danger_analysis = self._analyze_danger_moments(value_sequences)

                # æˆåŠŸç‡ä¸åºåˆ—ç‰¹å¾å…³ç³»
                completed_values = []
                for meta in value_metadata:
                    completed = meta['completed']
                    # å¤„ç†ä¸åŒçš„GameCompletedæ ¼å¼
                    if completed == True or completed == 'True' or completed == 1:
                        completed_values.append(1)
                    else:
                        completed_values.append(0)

                success_rate = np.mean(completed_values) if completed_values else 0

                pos_analysis[f'value_{value}'] = {
                    'sequence_count': len(value_sequences),
                    'success_rate': success_rate,
                    'patterns': patterns,
                    'danger_analysis': danger_analysis
                }

            dock_deep_analysis[pos] = pos_analysis

        self.results['dock_deep_analysis'] = dock_deep_analysis
        print("âœ… Dockåºåˆ—æ·±åº¦åˆ†æå®Œæˆ")
        return dock_deep_analysis

    def _identify_dock_patterns(self, sequences) -> Dict:
        """è¯†åˆ«Dockåºåˆ—æ¨¡å¼"""
        if not sequences:
            return {}

        # è®¡ç®—å¹³å‡åºåˆ—
        max_length = max(len(seq) for seq in sequences)
        avg_sequence = []

        for i in range(max_length):
            values_at_i = [seq[i] for seq in sequences if len(seq) > i]
            if values_at_i:
                avg_sequence.append(np.mean(values_at_i))

        # è¯†åˆ«æ¨¡å¼ç±»å‹
        if len(avg_sequence) < 3:
            return {'pattern_type': 'insufficient_data'}

        # åˆ¤æ–­è¶‹åŠ¿
        early_avg = np.mean(avg_sequence[:len(avg_sequence)//3])
        late_avg = np.mean(avg_sequence[2*len(avg_sequence)//3:])

        if late_avg > early_avg + 0.5:
            pattern_type = 'increasing_pressure'
        elif late_avg < early_avg - 0.5:
            pattern_type = 'decreasing_pressure'
        else:
            pattern_type = 'stable_pressure'

        return {
            'pattern_type': pattern_type,
            'avg_sequence': avg_sequence[:10],  # åªä¿å­˜å‰10ä¸ªç‚¹
            'early_avg': early_avg,
            'late_avg': late_avg
        }

    def _analyze_danger_moments(self, sequences) -> Dict:
        """åˆ†æå±é™©æ—¶åˆ»(Dock>=6)"""
        if not sequences:
            return {}

        danger_counts = []
        max_danger_levels = []

        for seq in sequences:
            danger_count = sum(1 for val in seq if val >= 6)
            max_danger = max(seq) if seq else 0

            danger_counts.append(danger_count)
            max_danger_levels.append(max_danger)

        return {
            'avg_danger_moments': np.mean(danger_counts),
            'max_danger_level': np.mean(max_danger_levels),
            'danger_frequency': np.mean([d > 0 for d in danger_counts])
        }

    def pressure_dynamics_analysis(self) -> Dict:
        """å‹åŠ›åŠ¨æ€åˆ†æ"""
        print("âš¡ æ‰§è¡Œå‹åŠ›åŠ¨æ€åˆ†æ...")

        pressure_dynamics = {}

        pressure_columns = ['PressureValueMean', 'PressureValueMax', 'PressureValueStdDev']

        for pos in ['pos1', 'pos2', 'pos3']:
            pos_dynamics = {}

            for value in range(1, 10):
                subset = self.data[self.features[pos] == value]

                if len(subset) < 10:
                    continue

                value_dynamics = {}

                for pressure_col in pressure_columns:
                    if pressure_col in subset.columns:
                        pressure_values = subset[pressure_col].dropna()

                        if len(pressure_values) > 0:
                            # åŸºç¡€ç»Ÿè®¡
                            stats = {
                                'mean': pressure_values.mean(),
                                'std': pressure_values.std(),
                                'median': pressure_values.median(),
                                'q75': pressure_values.quantile(0.75),
                                'q95': pressure_values.quantile(0.95),
                                'max': pressure_values.max()
                            }

                            # å‹åŠ›åˆ†å¸ƒåˆ†æ
                            low_pressure = (pressure_values < pressure_values.quantile(0.33)).sum()
                            high_pressure = (pressure_values > pressure_values.quantile(0.67)).sum()

                            pressure_distribution = {
                                'low_pressure_count': low_pressure,
                                'high_pressure_count': high_pressure,
                                'extreme_pressure_count': (pressure_values > pressure_values.quantile(0.9)).sum()
                            }

                            value_dynamics[pressure_col] = {
                                'statistics': stats,
                                'distribution': pressure_distribution
                            }

                pos_dynamics[f'value_{value}'] = value_dynamics

            pressure_dynamics[pos] = pos_dynamics

        self.results['pressure_dynamics'] = pressure_dynamics
        print("âœ… å‹åŠ›åŠ¨æ€åˆ†æå®Œæˆ")
        return pressure_dynamics

    def pattern_analysis(self) -> Dict:
        """é…ç½®æ¨¡å¼åˆ†æ"""
        print("ğŸ¯ æ‰§è¡Œé…ç½®æ¨¡å¼åˆ†æ...")

        patterns = {}

        # åºåˆ—æ¨¡å¼åˆ†æ
        sequence_patterns = {
            'increasing': self.data[self.features['is_increasing'] == 1],
            'decreasing': self.data[self.features['is_decreasing'] == 1],
            'uniform': self.data[self.features['is_uniform'] == 1],
            'mixed': self.data[(self.features['is_increasing'] == 0) &
                             (self.features['is_decreasing'] == 0) &
                             (self.features['is_uniform'] == 0)]
        }

        pattern_stats = {}
        for pattern_name, pattern_data in sequence_patterns.items():
            if len(pattern_data) > 0:
                stats_dict = {}
                for metric in self.target_metrics:
                    if metric in pattern_data.columns:
                        stats_dict[metric] = {
                            'mean': pattern_data[metric].mean(),
                            'std': pattern_data[metric].std(),
                            'count': len(pattern_data)
                        }
                pattern_stats[pattern_name] = stats_dict

        patterns['sequence_patterns'] = pattern_stats

        # æ•°å€¼åˆ†å¸ƒåˆ†æ
        value_analysis = {}
        for pos in ['pos1', 'pos2', 'pos3']:
            pos_analysis = {}
            for value in range(1, 10):
                value_data = self.data[self.features[pos] == value]
                if len(value_data) > 0:
                    value_stats = {}
                    for metric in self.target_metrics:
                        if metric in value_data.columns:
                            value_stats[metric] = {
                                'mean': value_data[metric].mean(),
                                'count': len(value_data)
                            }
                    pos_analysis[f'value_{value}'] = value_stats
            value_analysis[pos] = pos_analysis

        patterns['value_distribution'] = value_analysis

        self.results['patterns'] = patterns
        print("âœ… é…ç½®æ¨¡å¼åˆ†æå®Œæˆ")
        return patterns

    def build_prediction_models(self) -> Dict:
        """æ„å»ºé¢„æµ‹æ¨¡å‹"""
        print("ğŸ¤– æ„å»ºé¢„æµ‹æ¨¡å‹...")

        models = {}

        for metric in self.target_metrics:
            if metric not in self.data.columns:
                continue

            # æ•°æ®å‡†å¤‡
            X = self.features
            y = self.data[metric]

            # è®­ç»ƒæµ‹è¯•åˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )

            # æ•°æ®æ ‡å‡†åŒ–
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)

            # éšæœºæ£®æ—æ¨¡å‹
            rf_model = RandomForestRegressor(
                n_estimators=100,
                random_state=42,
                n_jobs=-1
            )

            rf_model.fit(X_train_scaled, y_train)

            # æ¨¡å‹è¯„ä¼°
            y_pred = rf_model.predict(X_test_scaled)
            r2 = r2_score(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))

            # ç‰¹å¾é‡è¦æ€§
            feature_importance = dict(zip(X.columns, rf_model.feature_importances_))

            models[metric] = {
                'model': rf_model,
                'scaler': scaler,
                'r2_score': r2,
                'rmse': rmse,
                'feature_importance': feature_importance
            }

        self.results['models'] = models
        print(f"âœ… é¢„æµ‹æ¨¡å‹æ„å»ºå®Œæˆï¼Œå…±{len(models)}ä¸ªæ¨¡å‹")
        return models

    def run_complete_analysis(self, output_dir: str = None) -> Dict:
        """è¿è¡Œå‡çº§ç‰ˆå®Œæ•´åˆ†ææµç¨‹"""
        print("ğŸš€ å¼€å§‹æ·±åº¦ä½“éªŒé…ç½®å½±å“åˆ†æ...")

        # æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
        self.load_and_preprocess()

        # åŸºç¡€åˆ†æ
        correlations = self.correlation_analysis()
        patterns = self.pattern_analysis()

        # é‡è¦ï¼šæ–°å¢DifficultyPositionå½±å“åˆ†æ
        difficulty_position_effects = self.difficulty_position_analysis()

        # æ·±åº¦åˆ†æï¼ˆæ–°å¢ï¼‰
        independent_effects = self.position_independent_analysis()
        interaction_effects = self.interaction_analysis()
        dynamic_effects = self.dynamic_impact_analysis()
        mechanism_effects = self.mechanism_analysis()

        # æ–°å¢æ·±åº¦åˆ†ææ–¹æ³•
        value_specific_effects = self.value_specific_analysis()
        gradient_effects = self.gradient_effect_analysis()
        dock_deep_effects = self.dock_sequence_deep_analysis()
        pressure_dynamics = self.pressure_dynamics_analysis()

        # æœºå™¨å­¦ä¹ å»ºæ¨¡
        models = self.build_prediction_models()

        # åˆ›å»ºå¢å¼ºå¯è§†åŒ–
        self.create_enhanced_visualizations(output_dir)

        # ç”Ÿæˆæ·±åº¦æŠ¥å‘Š
        report_path = self.generate_enhanced_report()

        # è¾“å‡ºå…³é”®å‘ç°
        self._print_key_findings()

        # æ±‡æ€»ç»“æœ
        summary = {
            'data_summary': {
                'total_records': len(self.data),
                'unique_configs': len(self.data[['pos1', 'pos2', 'pos3']].drop_duplicates()),
                'target_metrics': len(self.target_metrics)
            },
            'analysis_results': {
                'basic_analysis': len(correlations) > 0 and len(patterns) > 0,
                'advanced_analysis': len(independent_effects) > 0 and len(interaction_effects) > 0,
                'dynamic_analysis': len(dynamic_effects) > 0,
                'mechanism_analysis': len(mechanism_effects) > 0,
                'value_specific_analysis': len(value_specific_effects) > 0,
                'gradient_analysis': len(gradient_effects) > 0,
                'dock_deep_analysis': len(dock_deep_effects) > 0,
                'pressure_dynamics': len(pressure_dynamics) > 0,
                'models_completed': len(models) > 0,
                'best_model_r2': max([m['r2_score'] for m in models.values()]) if models else 0
            },
            'output_files': {
                'report_path': report_path,
                'charts_directory': output_dir or (
                    Path(self.csv_path).parent / "analysis_charts" if self.csv_path
                    else Path(self.csv_directory) / "analysis_output"
                )
            }
        }

        print("ğŸ‰ æ·±åº¦åˆ†ææµç¨‹æ‰§è¡Œå®Œæˆ!")
        print(f"ğŸ“„ æŠ¥å‘Šè·¯å¾„: {summary['output_files']['report_path']}")
        print(f"ğŸ“Š å›¾è¡¨ç›®å½•: {summary['output_files']['charts_directory']}")

        return summary

    def create_enhanced_visualizations(self, output_dir: str = None):
        """åˆ›å»ºå¢å¼ºå¯è§†åŒ–å›¾è¡¨"""
        print("ğŸ“Š åˆ›å»ºå¢å¼ºå¯è§†åŒ–å›¾è¡¨...", flush=True)

        if output_dir is None:
            # å¤šæ–‡ä»¶æ¨¡å¼ä½¿ç”¨csv_directoryï¼Œå•æ–‡ä»¶æ¨¡å¼ä½¿ç”¨csv_path
            if self.csv_path:
                output_dir = Path(self.csv_path).parent / "analysis_charts"
            else:
                output_dir = Path(self.csv_directory) / "analysis_output"

        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)

        # å®‰å…¨å›¾è¡¨ç»˜åˆ¶åˆ—è¡¨
        charts = [
            ("ä½ç½®ç›¸å…³æ€§çƒ­åŠ›å›¾", self._plot_position_correlation_heatmap),
            ("é…ç½®æ¨¡å¼ç®±çº¿å›¾", self._plot_pattern_boxplots),
            ("ç‰¹å¾é‡è¦æ€§å›¾", self._plot_feature_importance),
            ("é…ç½®åˆ†å¸ƒå›¾", self._plot_config_distribution),
            ("æ¨¡å‹æ€§èƒ½å›¾", self._plot_model_performance),
            ("DifficultyPositionå½±å“åˆ†æå›¾", self._plot_difficulty_position_analysis),
            ("ä½ç½®ç‹¬ç«‹æ•ˆåº”å›¾", self._plot_independent_effects),
            ("äº¤äº’æ•ˆåº”å›¾", self._plot_interaction_effects),
            ("æœºåˆ¶åˆ†æå›¾", self._plot_mechanism_analysis),
            ("æ•°å€¼å½±å“çŸ©é˜µçƒ­åŠ›å›¾", self._plot_value_impact_heatmaps),
            ("æ•°å€¼æ¢¯åº¦æ•ˆåº”æ›²çº¿", self._plot_gradient_curves),
            ("Dockåºåˆ—æ¨¡å¼å›¾", self._plot_dock_sequence_patterns),
            ("å‹åŠ›åŠ¨æ€åˆ†å¸ƒå›¾", self._plot_pressure_dynamics)
        ]

        successful_charts = 0
        for chart_name, chart_func in charts:
            try:
                print(f"   ç»˜åˆ¶ {chart_name}...", end='', flush=True)
                chart_func(output_path)
                successful_charts += 1
                print(f" âœ… å®Œæˆ", flush=True)
            except Exception as e:
                print(f"   âŒ {chart_name} å¤±è´¥: {str(e)}")
                continue

        print(f"âœ… å¢å¼ºå¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {output_path}")
        print(f"ğŸ“Š æˆåŠŸç»˜åˆ¶: {successful_charts}/{len(charts)} ä¸ªå›¾è¡¨")

    def _plot_independent_effects(self, output_path: Path):
        """ç»˜åˆ¶ä½ç½®ç‹¬ç«‹æ•ˆåº”å›¾"""
        if 'independent_effects' not in self.results:
            return

        fig, axes = plt.subplots(1, 3, figsize=(18, 6))

        for i, pos in enumerate(['pos1', 'pos2', 'pos3']):
            if pos in self.results['independent_effects']:
                effects = self.results['independent_effects'][pos]

                if 'DifficultyScore' in effects:
                    marginal_data = effects['DifficultyScore']['marginal_effects']
                    if marginal_data:
                        x_vals, y_vals = zip(*marginal_data)
                        axes[i].plot(x_vals, y_vals, 'o-', linewidth=2, markersize=8)
                        axes[i].set_title(f'{pos} Marginal Effect on DifficultyScore')
                        axes[i].set_xlabel(f'{pos} Value')
                        axes[i].set_ylabel('DifficultyScore Mean')
                        axes[i].grid(True, alpha=0.3)

        plt.suptitle('Position Independent Effects Analysis', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(output_path / 'independent_effects.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_interaction_effects(self, output_path: Path):
        """ç»˜åˆ¶äº¤äº’æ•ˆåº”å¼ºåº¦å›¾ï¼Œå¢åŠ æ•°å€¼èŒƒå›´æ£€æŸ¥"""
        if 'interaction_effects' not in self.results:
            return

        pairs = list(self.results['interaction_effects'].keys())
        metrics = ['DifficultyScore', 'PeakDockCount']

        if not pairs:
            print("   âš ï¸ æ— äº¤äº’æ•ˆåº”æ•°æ®ï¼Œè·³è¿‡ç»˜åˆ¶")
            return

        # æ”¶é›†æ‰€æœ‰æ•°å€¼å¹¶æ£€æŸ¥èŒƒå›´
        all_strengths = []
        for pair in pairs:
            for metric in metrics:
                if metric in self.results['interaction_effects'][pair]:
                    strength = self.results['interaction_effects'][pair][metric]['interaction_strength']
                    if np.isfinite(strength):  # æ£€æŸ¥æ•°å€¼æœ‰æ•ˆæ€§
                        all_strengths.append(abs(strength))

        if not all_strengths:
            print("   âš ï¸ æ— æœ‰æ•ˆäº¤äº’æ•ˆåº”å¼ºåº¦æ•°æ®ï¼Œè·³è¿‡ç»˜åˆ¶")
            return

        # æ£€æŸ¥æ•°å€¼èŒƒå›´åˆç†æ€§
        max_strength = max(all_strengths)
        if max_strength > 1e6:  # å¼‚å¸¸å¤§æ•°å€¼
            print(f"   âš ï¸ æ£€æµ‹åˆ°å¼‚å¸¸å¤§æ•°å€¼({max_strength:.2e})ï¼Œè·³è¿‡äº¤äº’æ•ˆåº”å›¾ç»˜åˆ¶")
            return

        try:
            fig, ax = plt.subplots(figsize=(min(12, len(pairs) * 2), 6))

            x_pos = np.arange(len(pairs))
            width = 0.35

            for i, metric in enumerate(metrics):
                strengths = []
                for pair in pairs:
                    if metric in self.results['interaction_effects'][pair]:
                        strength = self.results['interaction_effects'][pair][metric]['interaction_strength']
                        # æ•°å€¼å®‰å…¨æ£€æŸ¥
                        if np.isfinite(strength):
                            strengths.append(max(0, min(1, abs(strength))))  # é™åˆ¶åœ¨[0,1]èŒƒå›´
                        else:
                            strengths.append(0)
                    else:
                        strengths.append(0)

                if any(s > 0 for s in strengths):  # åªç»˜åˆ¶æœ‰æ•°æ®çš„æŒ‡æ ‡
                    bars = ax.bar(x_pos + i * width, strengths, width, label=metric, alpha=0.7)

                    # æ·»åŠ æ•°å€¼æ ‡ç­¾
                    for bar, strength in zip(bars, strengths):
                        if strength > 0.001:  # åªæ˜¾ç¤ºæ˜¾è‘—å€¼
                            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max_strength*0.01,
                                   f'{strength:.3f}', ha='center', va='bottom', fontsize=9)

            ax.set_xlabel('Position Combination')
            ax.set_ylabel('Interaction Effect Strength')
            ax.set_title('Position Interaction Effects Analysis')
            ax.set_xticks(x_pos + width / 2)
            ax.set_xticklabels(pairs, rotation=45 if len(pairs) > 3 else 0)
            ax.legend()
            ax.grid(True, alpha=0.3)

            # è®¾ç½®åˆç†çš„Yè½´èŒƒå›´
            ax.set_ylim(0, max(all_strengths) * 1.1)

            plt.tight_layout()
            plt.savefig(output_path / 'interaction_effects.png', dpi=300, bbox_inches='tight')
            plt.close()

        except Exception as e:
            print(f"   âŒ äº¤äº’æ•ˆåº”å›¾ç»˜åˆ¶å†…éƒ¨é”™è¯¯: {str(e)}")
            plt.close('all')  # ç¡®ä¿æ¸…ç†èµ„æº

    def _plot_mechanism_analysis(self, output_path: Path):
        """ç»˜åˆ¶æœºåˆ¶åˆ†æå›¾"""
        if 'mechanism_effects' not in self.results:
            return

        fig, axes = plt.subplots(1, 3, figsize=(18, 6))

        for i, pos in enumerate(['pos1', 'pos2', 'pos3']):
            if pos in self.results['mechanism_effects']:
                mechanism = self.results['mechanism_effects'][pos]

                if 'mediation_effects' in mechanism:
                    mediators = list(mechanism['mediation_effects'].keys())
                    strengths = [mechanism['mediation_effects'][m]['mediation_strength']
                               for m in mediators]

                    colors = ['red' if s > 0 else 'blue' for s in strengths]
                    bars = axes[i].barh(mediators, [abs(s) for s in strengths], color=colors, alpha=0.7)

                    axes[i].set_title(f'{pos} Mediation Effect Analysis')
                    axes[i].set_xlabel('Mediation Effect Strength')

                    # æ·»åŠ æ•°å€¼æ ‡ç­¾
                    for bar, strength in zip(bars, strengths):
                        axes[i].text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,
                                   f'{strength:.3f}', va='center', fontsize=9)

        plt.suptitle('å½±å“æœºåˆ¶ä¸­ä»‹è·¯å¾„åˆ†æ', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(output_path / 'mechanism_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()

    def generate_enhanced_report(self, output_path: str = None) -> str:
        """ç”Ÿæˆå¢å¼ºç‰ˆåˆ†ææŠ¥å‘Š"""
        print("ğŸ“‹ ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š...", flush=True)

        if output_path is None:
            # å¤šæ–‡ä»¶æ¨¡å¼ä½¿ç”¨csv_directoryï¼Œå•æ–‡ä»¶æ¨¡å¼ä½¿ç”¨csv_path
            if self.csv_path:
                output_path = Path(self.csv_path).parent / "enhanced_analysis_report.md"
            else:
                output_path = Path(self.csv_directory) / "enhanced_analysis_report.md"

        report = []
        report.append("# ä½“éªŒæ¨¡å¼é…ç½®[x,y,z]æ·±åº¦å½±å“åˆ†ææŠ¥å‘Š\n")
        report.append("## ğŸ“– æŠ¥å‘Šè¯´æ˜\n")
        report.append("æœ¬æŠ¥å‘Šåˆ†æä½“éªŒé…ç½®[x,y,z]ä¸‰ä¸ªä½ç½®çš„æ•°å€¼å¯¹æ¸¸æˆå„é¡¹æŒ‡æ ‡çš„å½±å“ã€‚")
        report.append("ä½“éªŒé…ç½®æ˜¯æ¸¸æˆéš¾åº¦è°ƒèŠ‚çš„é‡è¦å‚æ•°ï¼Œé€šè¿‡åˆ†æä¸åŒé…ç½®ä¸‹çš„æ¸¸æˆè¡¨ç°ï¼Œ")
        report.append("å¯ä»¥å¸®åŠ©ä¼˜åŒ–æ¸¸æˆå¹³è¡¡æ€§å’Œç©å®¶ä½“éªŒã€‚\n")

        report.append("### ğŸ“Š åˆ†æç»´åº¦è¯´æ˜")
        report.append("- **DifficultyScore**: æ¸¸æˆéš¾åº¦è¯„åˆ†ï¼Œæ•°å€¼è¶Šé«˜è¡¨ç¤ºéš¾åº¦è¶Šå¤§")
        report.append("- **PeakDockCount**: DockåŒºåŸŸç“¦ç‰‡æ•°é‡å³°å€¼ï¼Œåæ˜ æ¸¸æˆä¸­çš„å‹åŠ›æƒ…å†µ")
        report.append("- **PressureValueMean**: å¹³å‡å‹åŠ›å€¼ï¼Œè¡¡é‡æ¸¸æˆæ•´ä½“å‹åŠ›æ°´å¹³")
        report.append("- **DifficultyPosition**: å…³å¡æµç¨‹å†…éš¾ç‚¹å‡ºç°çš„ä½ç½®ã€‚æ•°å€¼èŒƒå›´0-1ï¼Œå…¶ä¸­0è¡¨ç¤ºéš¾ç‚¹åœ¨æœ€å‰é¢ï¼Œ0.99è¡¨ç¤ºéš¾ç‚¹åœ¨æœ€åé¢ï¼Œ1è¡¨ç¤ºæ— æ˜æ˜¾éš¾ç‚¹ä½ç½®")
        report.append("- **æˆåŠŸç‡**: ç©å®¶å®Œæˆæ¸¸æˆçš„æ¯”ä¾‹ï¼Œæ˜¯æœ€é‡è¦çš„ä½“éªŒæŒ‡æ ‡\n")

        report.append("### ğŸ¯ é…ç½®ä½ç½®è¯´æ˜")
        report.append("- **pos1**: é…ç½®æ•°ç»„ç¬¬ä¸€ä¸ªä½ç½®ï¼Œä¸»è¦å½±å“æ¸¸æˆå‰æœŸéš¾åº¦")
        report.append("- **pos2**: é…ç½®æ•°ç»„ç¬¬äºŒä¸ªä½ç½®ï¼Œä¸»è¦å½±å“æ¸¸æˆä¸­æœŸéš¾åº¦")
        report.append("- **pos3**: é…ç½®æ•°ç»„ç¬¬ä¸‰ä¸ªä½ç½®ï¼Œä¸»è¦å½±å“æ¸¸æˆåæœŸéš¾åº¦")
        report.append("- **æ•°å€¼èŒƒå›´**: 1-9ï¼Œæ•°å€¼è¶Šå°éš¾åº¦è¶Šä½ï¼Œæ•°å€¼è¶Šå¤§éš¾åº¦è¶Šé«˜\n")

        # æ•°æ®æºä¿¡æ¯
        if self.csv_path:
            report.append(f"**æ•°æ®æº**: {self.csv_path}")
        else:
            report.append(f"**æ•°æ®æº**: {self.csv_directory} ({len(self.csv_files)}ä¸ªCSVæ–‡ä»¶)")

        report.append(f"**åˆ†ææ—¶é—´**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"**æ ·æœ¬æ•°é‡**: {len(self.data):,}æ¡\n")

        # æ•°æ®æ¦‚è§ˆ
        self._add_data_overview(report)

        # DifficultyPositionå½±å“åˆ†æ (æ–°å¢)
        self._add_difficulty_position_effects_report(report)

        # ä½ç½®ç‹¬ç«‹æ•ˆåº”åˆ†æ
        self._add_independent_effects_report(report)

        # äº¤äº’æ•ˆåº”åˆ†æ
        self._add_interaction_effects_report(report)

        # åŠ¨æ€å½±å“åˆ†æ
        self._add_dynamic_effects_report(report)

        # æœºåˆ¶åˆ†æ
        self._add_mechanism_effects_report(report)

        # æ–°å¢æ·±åº¦åˆ†ææŠ¥å‘Š
        self._add_value_specific_report(report)
        self._add_gradient_effects_report(report)
        self._add_dock_sequence_report(report)
        self._add_pressure_dynamics_report(report)

        # å…³é”®å‘ç°ä¸å»ºè®®
        self._add_key_findings_and_recommendations(report)

        # å†™å…¥æ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))

        print(f"âœ… æ·±åº¦åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        return str(output_path)
    

    def _add_data_overview(self, report):
        report.append("## ğŸ“Š æ•°æ®æ¦‚è§ˆ\n")
        report.append(f"- é…ç½®èŒƒå›´: pos1=[{self.features['pos1'].min()}-{self.features['pos1'].max()}], " +
                     f"pos2=[{self.features['pos2'].min()}-{self.features['pos2'].max()}], " +
                     f"pos3=[{self.features['pos3'].min()}-{self.features['pos3'].max()}]")
        report.append(f"- å”¯ä¸€é…ç½®æ•°: {len(self.data[['pos1', 'pos2', 'pos3']].drop_duplicates())}ç§")

    def _add_independent_effects_report(self, report):
        if 'independent_effects' not in self.results:
            return

        report.append("\n## ğŸ¯ ä½ç½®ç‹¬ç«‹æ•ˆåº”åˆ†æ\n")
        report.append("### ğŸ“ åˆ†æè¯´æ˜")
        report.append("ä½ç½®ç‹¬ç«‹æ•ˆåº”åˆ†ææ—¨åœ¨è¯†åˆ«æ¯ä¸ªé…ç½®ä½ç½®å¯¹æ¸¸æˆæŒ‡æ ‡çš„å•ç‹¬å½±å“ï¼Œ")
        report.append("æ§åˆ¶å…¶ä»–å˜é‡çš„æƒ…å†µä¸‹ï¼Œè§‚å¯Ÿå•ä¸ªä½ç½®æ•°å€¼å˜åŒ–æ—¶æŒ‡æ ‡çš„è¾¹é™…å˜åŒ–ã€‚")
        report.append("è¾¹é™…æ•ˆåº”è¡¨ç¤ºè¯¥ä½ç½®æ•°å€¼æ¯å¢åŠ 1ä¸ªå•ä½æ—¶ï¼Œç›®æ ‡æŒ‡æ ‡çš„å¹³å‡å˜åŒ–é‡ã€‚\n")

        for pos in ['pos1', 'pos2', 'pos3']:
            if pos in self.results['independent_effects']:
                effects = self.results['independent_effects'][pos]
                report.append(f"### {pos}çš„ç‹¬ç«‹æ•ˆåº”:")

                for metric, data in effects.items():
                    if 'avg_marginal_diff' in data:
                        avg_diff = data['avg_marginal_diff']
                        volatility = data['marginal_volatility']
                        report.append(f"- **{metric}**: å¹³å‡è¾¹é™…æ•ˆåº” {avg_diff:.3f}, æ³¢åŠ¨æ€§ {volatility:.3f}")

    def _add_interaction_effects_report(self, report):
        if 'interaction_effects' not in self.results:
            return

        report.append("\n## ğŸ”„ ä½ç½®äº¤äº’æ•ˆåº”åˆ†æ\n")
        report.append("### ğŸ“ åˆ†æè¯´æ˜")
        report.append("äº¤äº’æ•ˆåº”åˆ†ææ¢è®¨ä¸åŒé…ç½®ä½ç½®ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚å½“ä¸¤ä¸ªä½ç½®çš„ç»„åˆæ•ˆæœ")
        report.append("è¶…è¿‡å„è‡ªç‹¬ç«‹æ•ˆæœçš„ç®€å•ç›¸åŠ æ—¶ï¼Œå°±å­˜åœ¨äº¤äº’æ•ˆåº”ã€‚æ­£çš„äº¤äº’å¢ç›Šè¡¨ç¤º")
        report.append("ä¸¤ä¸ªä½ç½®ååŒä½œç”¨ï¼Œè´Ÿçš„äº¤äº’å¢ç›Šè¡¨ç¤ºä¸¤ä¸ªä½ç½®ç›¸äº’æŠµæ¶ˆã€‚\n")

        for pair, effects in self.results['interaction_effects'].items():
            report.append(f"### {pair}äº¤äº’æ•ˆåº”:")
            for metric, data in effects.items():
                gain = data['interaction_gain']
                strength = data['interaction_strength']
                report.append(f"- **{metric}**: äº¤äº’å¢ç›Š {gain:.4f}, æ•ˆåº”å¼ºåº¦ {strength:.4f}")

    def _add_dynamic_effects_report(self, report):
        if 'dynamic_effects' not in self.results:
            return

        report.append("\n## â±ï¸ åŠ¨æ€å½±å“åˆ†æ\n")

        for pos, dynamics in self.results['dynamic_effects'].items():
            report.append(f"### {pos}çš„æ—¶åºå½±å“:")
            for stage, corr in dynamics.items():
                stage_name = {'early_correlation': 'å‰æœŸ', 'middle_correlation': 'ä¸­æœŸ', 'late_correlation': 'åæœŸ'}.get(stage, stage)
                report.append(f"- **{stage_name}**: ç›¸å…³æ€§ {corr:.3f}")

    def _add_difficulty_position_effects_report(self, report):
        """æ·»åŠ DifficultyPositionå½±å“åˆ†ææŠ¥å‘Š - å¢å¼ºç‰ˆ"""
        if 'difficulty_position_effects' not in self.results:
            return

        report.append("\n## ğŸ† DifficultyPositionå½±å“åˆ†æ (å¢å¼ºç‰ˆ)\n")
        report.append("### ğŸ“ æŒ‡æ ‡è¯´æ˜ä¸é‡è¦æ€§")
        report.append("**DifficultyPosition** æ˜¯æ¸¸æˆä½“éªŒè®¾è®¡ä¸­çš„æ ¸å¿ƒæŒ‡æ ‡ï¼Œåæ˜ éš¾ç‚¹åœ¨æ¸¸æˆæµç¨‹ä¸­çš„å‡ºç°ä½ç½®ã€‚")
        report.append("è¯¥æŒ‡æ ‡ç›´æ¥å½±å“ç©å®¶çš„ä½“éªŒèŠ‚å¥ã€æŒ«è´¥æ„Ÿå’Œæˆå°±æ„Ÿçš„åˆ†å¸ƒï¼š")
        report.append("")
        report.append("**æ•°å€¼å«ä¹‰æ·±åº¦è§£æï¼š**")
        report.append("- **0.00-0.25**: å‰æœŸéš¾ç‚¹ - æ¸¸æˆå‰25%é˜¶æ®µå‡ºç°éš¾ç‚¹")
        report.append("- **0.25-0.50**: å‰ä¸­æœŸéš¾ç‚¹ - æ¸¸æˆ25%-50%é˜¶æ®µå‡ºç°éš¾ç‚¹")
        report.append("- **0.50-0.75**: åä¸­æœŸéš¾ç‚¹ - æ¸¸æˆ50%-75%é˜¶æ®µå‡ºç°éš¾ç‚¹")
        report.append("- **0.75-1.00**: åæœŸéš¾ç‚¹ - æ¸¸æˆå25%é˜¶æ®µå‡ºç°éš¾ç‚¹")
        report.append("- **1.00**: æ— æ˜æ˜¾éš¾ç‚¹ - ä½“éªŒå¹³æ»‘ï¼Œæ— æ˜æ˜¾å›°éš¾ç‚¹")
        report.append("")
        report.append("**ä½“éªŒè®¾è®¡åŸåˆ™ï¼š** å››é˜¶æ®µå‡åŒ€åˆ†å¸ƒï¼Œæ¯ä¸ªé˜¶æ®µå 25%çš„æ¸¸æˆè¿›ç¨‹ã€‚")
        report.append("")

        # è®¡ç®—å…¨å±€ç»Ÿè®¡
        all_positions = []
        for pos in ['pos1', 'pos2', 'pos3']:
            if pos in self.results['difficulty_position_effects'] and 'value_effects' in self.results['difficulty_position_effects'][pos]:
                for value, stats in self.results['difficulty_position_effects'][pos]['value_effects'].items():
                    all_positions.extend([stats['mean']] * stats['count'])

        if all_positions:
            global_mean = np.mean(all_positions)
            global_std = np.std(all_positions)
            stage1_ratio = sum(1 for p in all_positions if p < 0.25) / len(all_positions)
            stage2_ratio = sum(1 for p in all_positions if 0.25 <= p < 0.50) / len(all_positions)
            stage3_ratio = sum(1 for p in all_positions if 0.50 <= p < 0.75) / len(all_positions)
            stage4_ratio = sum(1 for p in all_positions if 0.75 <= p < 1.0) / len(all_positions)
            perfect_ratio = sum(1 for p in all_positions if abs(p - 1.0) < 0.01) / len(all_positions)

            report.append("### ğŸ“Š å…¨å±€DifficultyPositionåˆ†å¸ƒç‰¹å¾")
            report.append(f"- **æ•´ä½“å‡å€¼**: {global_mean:.3f}")
            report.append(f"- **æ ‡å‡†å·®**: {global_std:.3f}")
            report.append(f"- **å‰æœŸéš¾ç‚¹å æ¯” (0.00-0.25)**: {stage1_ratio:.1%}")
            report.append(f"- **å‰ä¸­æœŸéš¾ç‚¹å æ¯” (0.25-0.50)**: {stage2_ratio:.1%}")
            report.append(f"- **åä¸­æœŸéš¾ç‚¹å æ¯” (0.50-0.75)**: {stage3_ratio:.1%}")
            report.append(f"- **åæœŸéš¾ç‚¹å æ¯” (0.75-1.00)**: {stage4_ratio:.1%}")
            report.append(f"- **æ— éš¾ç‚¹å æ¯”**: {perfect_ratio:.1%}")
            report.append("")

        # è¯¦ç»†çš„ä½ç½®å½±å“åˆ†æ
        for pos in ['pos1', 'pos2', 'pos3']:
            if pos in self.results['difficulty_position_effects']:
                pos_data = self.results['difficulty_position_effects'][pos]
                report.append(f"### ğŸ¯ {pos.upper()}ä½ç½®çš„DifficultyPositionå½±å“è¯¦æ")

                # ç›¸å…³æ€§åˆ†æ
                if 'correlation' in pos_data:
                    corr_data = pos_data['correlation']
                    significance = "ç»Ÿè®¡æ˜¾è‘—" if corr_data['significant'] else "ç»Ÿè®¡ä¸æ˜¾è‘—"
                    corr_strength = "å¼ºç›¸å…³" if abs(corr_data['correlation']) > 0.5 else "ä¸­ç­‰ç›¸å…³" if abs(corr_data['correlation']) > 0.3 else "å¼±ç›¸å…³"
                    corr_direction = "æ­£ç›¸å…³(æ•°å€¼è¶Šå¤§éš¾ç‚¹è¶Šé å)" if corr_data['correlation'] > 0 else "è´Ÿç›¸å…³(æ•°å€¼è¶Šå¤§éš¾ç‚¹è¶Šé å‰)"

                    report.append(f"**æ€»ä½“ç›¸å…³æ€§åˆ†æï¼š**")
                    report.append(f"- ç›¸å…³ç³»æ•°: {corr_data['correlation']:.3f} ({corr_strength}ï¼Œ{corr_direction})")
                    report.append(f"- æ˜¾è‘—æ€§: p={corr_data['p_value']:.3f} ({significance})")
                    report.append("")

                # è¯¦ç»†çš„æ•°å€¼æ•ˆåº”åˆ†æ
                if 'value_effects' in pos_data:
                    value_effects = pos_data['value_effects']

                    report.append(f"**{pos.upper()}å„æ•°å€¼é…ç½®çš„DifficultyPositionå½±å“è¯¦è¡¨ï¼š**")
                    report.append("| é…ç½®å€¼ | å¹³å‡ä½ç½® | æ ‡å‡†å·® | ä¸­ä½æ•° | æ ·æœ¬æ•° | ä½ç½®ç‰¹å¾ | ä½“éªŒè¯„ä»· |")
                    report.append("|--------|----------|--------|--------|--------|----------|----------|")

                    for value in sorted(value_effects.keys()):
                        stats = value_effects[value]
                        mean_pos = stats['mean']

                        # ä½ç½®ç‰¹å¾æè¿°
                        if mean_pos < 0.25:
                            pos_feature = "å‰æœŸéš¾ç‚¹"
                            experience_eval = "Stage 1"
                        elif mean_pos < 0.50:
                            pos_feature = "å‰ä¸­æœŸéš¾ç‚¹"
                            experience_eval = "Stage 2"
                        elif mean_pos < 0.75:
                            pos_feature = "åä¸­æœŸéš¾ç‚¹"
                            experience_eval = "Stage 3"
                        elif mean_pos < 1.0:
                            pos_feature = "åæœŸéš¾ç‚¹"
                            experience_eval = "Stage 4"
                        else:
                            pos_feature = "æ— æ˜æ˜¾éš¾ç‚¹"
                            experience_eval = "No Difficulty"

                        report.append(f"| {value} | {mean_pos:.3f} | {stats['std']:.3f} | {stats['median']:.3f} | {stats['count']} | {pos_feature} | {experience_eval} |")

                    report.append("")

                # é…ç½®æ¨èåˆ†æ - åŸºäºæ•°æ®ç‰¹å¾è€Œéç®€å•æ¨è/ä¸æ¨è
                if 'value_effects' in pos_data:
                    # æŒ‰ç…§DifficultyPositionè¿›è¡Œæ’åºå’Œåˆ†ç±»
                    sorted_configs = sorted(value_effects.items(), key=lambda x: x[1]['mean'])

                    report.append(f"**{pos.upper()}é…ç½®æ•ˆæœæ’åºåˆ†æ (æŒ‰DifficultyPositionä»æ—©åˆ°æ™š)ï¼š**")

                    for i, (value, stats) in enumerate(sorted_configs):
                        rank = i + 1
                        mean_pos = stats['mean']
                        sample_count = stats['count']

                        # è¯¦ç»†çš„ç‰¹å¾æè¿°
                        if mean_pos < 0.25:
                            characteristic = f"ä½¿éš¾ç‚¹åœ¨å‰æœŸå‡ºç°(ä½ç½®{mean_pos:.3f})"
                        elif mean_pos < 0.50:
                            characteristic = f"ä½¿éš¾ç‚¹åœ¨å‰ä¸­æœŸå‡ºç°(ä½ç½®{mean_pos:.3f})"
                        elif mean_pos < 0.75:
                            characteristic = f"ä½¿éš¾ç‚¹åœ¨åä¸­æœŸå‡ºç°(ä½ç½®{mean_pos:.3f})"
                        elif mean_pos < 1.0:
                            characteristic = f"ä½¿éš¾ç‚¹åœ¨åæœŸå‡ºç°(ä½ç½®{mean_pos:.3f})"
                        else:
                            characteristic = f"ä½¿å…³å¡ç¼ºä¹æ˜æ˜¾éš¾ç‚¹(ä½ç½®{mean_pos:.3f})"

                        confidence = "é«˜ç½®ä¿¡åº¦" if sample_count > 100 else "ä¸­ç½®ä¿¡åº¦" if sample_count > 30 else "ä½ç½®ä¿¡åº¦"

                        report.append(f"{rank}. **é…ç½®å€¼{value}**: {characteristic}")
                        report.append(f"   - æ•°æ®ç½®ä¿¡åº¦: {confidence} (æ ·æœ¬æ•°:{sample_count})")
                        report.append("")

                # é…ç½®åˆ†ç±»ç»Ÿè®¡ - å¢å¼ºç‰ˆ
                categories = [
                    ('no_difficulty', 'æ— æ˜æ˜¾éš¾ç‚¹é…ç½®', 'ä½“éªŒå¹³æ»‘ä½†å¯èƒ½ç¼ºä¹æŒ‘æˆ˜'),
                    ('early_difficulty', 'å‰æœŸéš¾ç‚¹é…ç½®', 'å¼€å±€æŒ‘æˆ˜å‹ï¼Œéœ€æ³¨æ„æŒ«è´¥æ„Ÿæ§åˆ¶'),
                    ('mid_difficulty', 'ä¸­æœŸéš¾ç‚¹é…ç½®', 'æ¸è¿›å¼æŒ‘æˆ˜ï¼Œæ¨èçš„ä½“éªŒèŠ‚å¥'),
                    ('late_difficulty', 'åæœŸéš¾ç‚¹é…ç½®', 'åå‘åˆ¶äººå‹ï¼Œé€‚åˆæ„å»ºå±‚æ¬¡æ„Ÿ')
                ]

                report.append(f"**{pos.upper()}é…ç½®ç±»å‹åˆ†å¸ƒç»Ÿè®¡ï¼š**")
                for category_key, category_name, category_desc in categories:
                    config_key = f'{category_key}_configs'
                    if config_key in pos_data:
                        config_info = pos_data[config_key]
                        values_str = ', '.join(map(str, sorted(config_info['values'])))
                        avg_pos = config_info['avg_position']
                        count = config_info['count']
                        proportion = count / len(value_effects) if value_effects else 0

                        report.append(f"- **{category_name}** ({proportion:.1%}): é…ç½®å€¼[{values_str}]")
                        report.append(f"  - å¹³å‡DifficultyPosition: {avg_pos:.3f}")
                        report.append(f"  - è®¾è®¡ç‰¹ç‚¹: {category_desc}")
                        report.append("")

        # äº¤äº’æ•ˆåº”åˆ†æ - å¢å¼ºç‰ˆ
        if 'interaction_effects' in self.results['difficulty_position_effects']:
            interaction_data = self.results['difficulty_position_effects']['interaction_effects']
            if interaction_data:
                report.append("### ğŸ”„ ä½ç½®é—´äº¤äº’æ•ˆåº”å¯¹DifficultyPositionçš„å½±å“")
                report.append("**äº¤äº’æ•ˆåº”è¯´æ˜**: è¡¡é‡ä¸åŒä½ç½®é…ç½®ç»„åˆæ—¶äº§ç”Ÿçš„ååŒæˆ–å†²çªæ•ˆåº”ï¼Œæ­£å€¼è¡¨ç¤ºååŒå¢å¼ºï¼Œè´Ÿå€¼è¡¨ç¤ºç›¸äº’æŠµæ¶ˆã€‚")
                report.append("")

                sorted_interactions = sorted(interaction_data.items(), key=lambda x: x[1]['interaction_gain'], reverse=True)

                for pair, data in sorted_interactions:
                    gain = data['interaction_gain']
                    r2_base = data['r2_base']
                    r2_inter = data['r2_interaction']
                    sample_count = data['sample_count']

                    if gain > 0.01:
                        effect_desc = "æ˜¾è‘—ååŒæ•ˆåº”"
                        impact_desc = "ä½ç½®é—´é…ç½®äº§ç”Ÿå åŠ å¢å¼º"
                    elif gain > 0.005:
                        effect_desc = "è½»å¾®ååŒæ•ˆåº”"
                        impact_desc = "ä½ç½®é—´é…ç½®ç•¥æœ‰ååŒ"
                    elif gain > -0.005:
                        effect_desc = "æ— æ˜æ˜¾äº¤äº’"
                        impact_desc = "ä½ç½®é—´ç›¸å¯¹ç‹¬ç«‹"
                    elif gain > -0.01:
                        effect_desc = "è½»å¾®å†²çªæ•ˆåº”"
                        impact_desc = "ä½ç½®é—´é…ç½®ç•¥æœ‰æŠµæ¶ˆ"
                    else:
                        effect_desc = "æ˜¾è‘—å†²çªæ•ˆåº”"
                        impact_desc = "ä½ç½®é—´é…ç½®ç›¸äº’å¹²æ‰°"

                    report.append(f"**{pair}äº¤äº’åˆ†æ:**")
                    report.append(f"- äº¤äº’å¢ç›Š: {gain:.4f} ({effect_desc})")
                    report.append(f"- æ¨¡å‹æ”¹è¿›: {r2_base:.3f} â†’ {r2_inter:.3f}")
                    report.append(f"- æ•ˆåº”è§£é‡Š: {impact_desc}")
                    report.append(f"- æ ·æœ¬è§„æ¨¡: {sample_count}")
                    report.append("")


    def _add_mechanism_effects_report(self, report):
        if 'mechanism_effects' not in self.results:
            return

        report.append("\n## ğŸ” å½±å“æœºåˆ¶åˆ†æ (å¢å¼ºç‰ˆ)\n")
        report.append("### ğŸ“ æœºåˆ¶åˆ†æç†è®ºåŸºç¡€")
        report.append("**å½±å“æœºåˆ¶åˆ†æ** æ˜¯ä¸€ç§æ·±åº¦è§£æä½“éªŒé…ç½®å¦‚ä½•äº§ç”Ÿæœ€ç»ˆæ•ˆæœçš„æ–¹æ³•è®ºã€‚è¯¥åˆ†æåŸºäºä¸­ä»‹æ•ˆåº”ç†è®ºï¼Œ")
        report.append("æ—¨åœ¨è¯†åˆ«é…ç½®å½±å“æ¸¸æˆæŒ‡æ ‡çš„å…·ä½“è·¯å¾„å’Œä¸­é—´ç¯èŠ‚ã€‚")
        report.append("")
        report.append("**æ ¸å¿ƒæ¦‚å¿µè¯´æ˜ï¼š**")
        report.append("- **ç›´æ¥æ•ˆåº”(Direct Effect)**: é…ç½®ä½ç½®ç›´æ¥å¯¹ç›®æ ‡æŒ‡æ ‡äº§ç”Ÿçš„å½±å“ï¼Œä¸é€šè¿‡å…¶ä»–ä¸­é—´å˜é‡")
        report.append("- **ä¸­ä»‹æ•ˆåº”(Mediation Effect)**: é…ç½®é€šè¿‡å½±å“ä¸­é—´å˜é‡ï¼Œå†ç”±ä¸­é—´å˜é‡å½±å“ç›®æ ‡æŒ‡æ ‡çš„é—´æ¥è·¯å¾„")
        report.append("- **æ€»æ•ˆåº”(Total Effect)**: ç›´æ¥æ•ˆåº” + æ‰€æœ‰ä¸­ä»‹æ•ˆåº”çš„æ€»å’Œ")
        report.append("- **ä¸­ä»‹è·¯å¾„å¼ºåº¦**: è¡¡é‡ç‰¹å®šä¸­ä»‹è·¯å¾„å¯¹æ€»å½±å“çš„è´¡çŒ®åº¦ï¼Œæ•°å€¼è¶Šå¤§è´¡çŒ®è¶Šå¤§")
        report.append("")
        report.append("**å®è·µä»·å€¼ï¼š**")
        report.append("- ç†è§£WHYï¼šä¸ä»…çŸ¥é“\"é…ç½®Xå½±å“æŒ‡æ ‡Y\"ï¼Œè¿˜çŸ¥é“\"æ˜¯é€šè¿‡ä»€ä¹ˆæœºåˆ¶å½±å“çš„\"")
        report.append("- ç²¾å‡†ä¼˜åŒ–ï¼šé’ˆå¯¹å…·ä½“æœºåˆ¶è¿›è¡Œä¼˜åŒ–ï¼Œè€Œéç›²ç›®è°ƒæ•´é…ç½®")
        report.append("- å‰¯ä½œç”¨é¢„æµ‹ï¼šäº†è§£è°ƒæ•´æŸä¸ªé…ç½®å¯èƒ½å¯¹å…¶ä»–æŒ‡æ ‡äº§ç”Ÿçš„è¿é”å½±å“")
        report.append("")

        for pos, mechanism in self.results['mechanism_effects'].items():
            report.append(f"### ğŸ¯ {pos.upper()}ä½ç½®çš„å½±å“æœºåˆ¶æ·±åº¦è§£æ")

            if 'direct_effect' in mechanism:
                direct_effect = mechanism['direct_effect']
                effect_strength = "å¼ºç›´æ¥å½±å“" if abs(direct_effect) > 0.3 else "ä¸­ç­‰ç›´æ¥å½±å“" if abs(direct_effect) > 0.1 else "å¼±ç›´æ¥å½±å“"
                effect_direction = "æ­£å‘æ¨åŠ¨" if direct_effect > 0 else "è´Ÿå‘æŠ‘åˆ¶"

                report.append(f"**ç›´æ¥æ•ˆåº”åˆ†æ:**")
                report.append(f"- ç›´æ¥æ•ˆåº”ç³»æ•°: {direct_effect:.3f} ({effect_strength}ï¼Œ{effect_direction})")
                report.append(f"- æ•ˆåº”è§£é‡Š: {pos.upper()}é…ç½®æ¯å¢åŠ 1ä¸ªå•ä½ï¼Œç›®æ ‡æŒ‡æ ‡{('å¢åŠ ' if direct_effect > 0 else 'å‡å°‘')}{abs(direct_effect):.3f}ä¸ªå•ä½")

                if abs(direct_effect) > 0.2:
                    report.append(f"- **è®¾è®¡å»ºè®®**: è¯¥ä½ç½®å¯¹ç›®æ ‡æŒ‡æ ‡æœ‰æ˜¾è‘—ç›´æ¥å½±å“ï¼Œæ˜¯å…³é”®è°ƒèŠ‚ç‚¹")
                elif abs(direct_effect) > 0.1:
                    report.append(f"- **è®¾è®¡å»ºè®®**: è¯¥ä½ç½®æœ‰ä¸­ç­‰ç¨‹åº¦çš„ç›´æ¥å½±å“ï¼Œå¯ä½œä¸ºå¾®è°ƒå‚æ•°")
                else:
                    report.append(f"- **è®¾è®¡å»ºè®®**: è¯¥ä½ç½®ç›´æ¥å½±å“è¾ƒå°ï¼Œä¸»è¦é€šè¿‡ä¸­ä»‹æœºåˆ¶å‘æŒ¥ä½œç”¨")
                report.append("")

            if 'strongest_mediation_path' in mechanism:
                strongest = mechanism['strongest_mediation_path']
                mediator = strongest['mediator']
                strength = strongest['strength']

                # ä¸­ä»‹å˜é‡å«ä¹‰è§£é‡Š
                mediator_explanations = {
                    'PeakDockCount': 'æ¸¸æˆè¿‡ç¨‹ä¸­DockåŒºåŸŸçš„æœ€å¤§ç“¦ç‰‡æ•°é‡ï¼Œåæ˜ æ¸¸æˆè¿‡ç¨‹çš„å¤æ‚ç¨‹åº¦å’Œå‹åŠ›å³°å€¼',
                    'PressureValueMean': 'æ¸¸æˆå…¨ç¨‹å‹åŠ›å€¼çš„å¹³å‡æ°´å¹³ï¼Œè¡¡é‡æ•´ä½“æ¸¸æˆéš¾åº¦å’Œå‹è¿«æ„Ÿ',
                    'PressureValueMax': 'æ¸¸æˆè¿‡ç¨‹ä¸­çš„æœ€å¤§å‹åŠ›å€¼ï¼Œåæ˜ æ¸¸æˆçš„éš¾åº¦å³°å€¼',
                    'PressureValueStdDev': 'å‹åŠ›å€¼çš„æ ‡å‡†å·®ï¼Œè¡¡é‡æ¸¸æˆéš¾åº¦æ³¢åŠ¨çš„å‰§çƒˆç¨‹åº¦',
                    'InitialMinCost': 'æ¸¸æˆåˆæœŸçš„æœ€å°æ¶ˆé™¤æˆæœ¬ï¼Œåæ˜ å¼€å±€çš„éš¾æ˜“ç¨‹åº¦',
                    'FinalDifficulty': 'æ¸¸æˆæœ€ç»ˆéš¾åº¦è¯„åˆ†ï¼Œç»¼åˆè¡¡é‡å…³å¡çš„æ•´ä½“æŒ‘æˆ˜æ°´å¹³'
                }

                mediator_desc = mediator_explanations.get(mediator, f'{mediator}ç›¸å…³æŒ‡æ ‡')
                strength_level = "æ˜¾è‘—ä¸­ä»‹æ•ˆåº”" if abs(strength) > 0.2 else "ä¸­ç­‰ä¸­ä»‹æ•ˆåº”" if abs(strength) > 0.1 else "è½»å¾®ä¸­ä»‹æ•ˆåº”"

                report.append(f"**æœ€å¼ºä¸­ä»‹è·¯å¾„åˆ†æ:**")
                report.append(f"- ä¸­ä»‹å˜é‡: {mediator}")
                report.append(f"- ä¸­ä»‹å«ä¹‰: {mediator_desc}")
                report.append(f"- ä¸­ä»‹å¼ºåº¦: {strength:.3f} ({strength_level})")
                report.append(f"- **ä½œç”¨æœºåˆ¶**: {pos.upper()}é…ç½® â†’ å½±å“{mediator} â†’ {mediator}å½±å“ç›®æ ‡æŒ‡æ ‡")

                if abs(strength) > 0.15:
                    report.append(f"- **ä¼˜åŒ–ç­–ç•¥**: è¯¥ä¸­ä»‹è·¯å¾„æ˜¯ä¸»è¦å½±å“æœºåˆ¶ï¼Œè°ƒæ•´{pos.upper()}æ—¶éœ€é‡ç‚¹å…³æ³¨å¯¹{mediator}çš„å½±å“")
                else:
                    report.append(f"- **ä¼˜åŒ–ç­–ç•¥**: è¯¥ä¸­ä»‹è·¯å¾„å½±å“ç›¸å¯¹è¾ƒå°ï¼Œå¯ä½œä¸ºè¾…åŠ©ä¼˜åŒ–æ–¹å‘")

                # æ·»åŠ å…·ä½“çš„ä¼˜åŒ–å»ºè®®
                if mediator == 'PeakDockCount':
                    report.append(f"- **å…·ä½“å»ºè®®**: é€šè¿‡è°ƒæ•´{pos.upper()}æ¥æ§åˆ¶DockåŒºåŸŸå‹åŠ›ï¼Œé¿å…ç“¦ç‰‡å †ç§¯è¿‡å¤š")
                elif mediator == 'PressureValueMean':
                    report.append(f"- **å…·ä½“å»ºè®®**: é€šè¿‡{pos.upper()}è°ƒèŠ‚æ•´ä½“æ¸¸æˆå‹åŠ›æ°´å¹³ï¼Œä¿æŒæŒ‘æˆ˜ä¸ä½“éªŒçš„å¹³è¡¡")
                elif mediator == 'DifficultyPosition':
                    report.append(f"- **å…·ä½“å»ºè®®**: é€šè¿‡{pos.upper()}æ§åˆ¶éš¾ç‚¹å‡ºç°æ—¶æœºï¼Œä¼˜åŒ–æ¸¸æˆèŠ‚å¥")

                report.append("")

            # æ·»åŠ ç»¼åˆæœºåˆ¶è¯„ä¼°
            if 'direct_effect' in mechanism and 'strongest_mediation_path' in mechanism:
                direct = abs(mechanism['direct_effect'])
                indirect = abs(mechanism['strongest_mediation_path']['strength'])

                if direct > indirect * 1.5:
                    mechanism_type = "ç›´æ¥ä¸»å¯¼å‹"
                    mechanism_desc = f"è¯¥ä½ç½®ä¸»è¦é€šè¿‡ç›´æ¥æ•ˆåº”å½±å“ç›®æ ‡æŒ‡æ ‡ï¼Œä¸­ä»‹æ•ˆåº”ç›¸å¯¹è¾ƒå¼±"
                    optimization_focus = "é‡ç‚¹å…³æ³¨è¯¥ä½ç½®çš„ç›´æ¥è°ƒèŠ‚æ•ˆæœ"
                elif indirect > direct * 1.5:
                    mechanism_type = "ä¸­ä»‹ä¸»å¯¼å‹"
                    mechanism_desc = f"è¯¥ä½ç½®ä¸»è¦é€šè¿‡ä¸­ä»‹æœºåˆ¶å½±å“ç›®æ ‡æŒ‡æ ‡ï¼Œç›´æ¥æ•ˆåº”ç›¸å¯¹è¾ƒå°"
                    optimization_focus = f"é‡ç‚¹å…³æ³¨{mechanism['strongest_mediation_path']['mediator']}çš„å˜åŒ–"
                else:
                    mechanism_type = "æ··åˆå½±å“å‹"
                    mechanism_desc = f"è¯¥ä½ç½®é€šè¿‡ç›´æ¥å’Œä¸­ä»‹ä¸¤ç§æœºåˆ¶å…±åŒå½±å“ç›®æ ‡æŒ‡æ ‡"
                    optimization_focus = "éœ€è¦åŒæ—¶è€ƒè™‘ç›´æ¥æ•ˆåº”å’Œä¸­ä»‹æ•ˆåº”"

                report.append(f"**ç»¼åˆæœºåˆ¶è¯„ä¼°:**")
                report.append(f"- æœºåˆ¶ç±»å‹: {mechanism_type}")
                report.append(f"- æœºåˆ¶ç‰¹å¾: {mechanism_desc}")
                report.append(f"- ä¼˜åŒ–é‡ç‚¹: {optimization_focus}")
                report.append("")

        report.append("---")
        report.append("ğŸ’¡ **æœºåˆ¶åˆ†æåº”ç”¨æŒ‡å—:**")
        report.append("1. **ç›´æ¥ä¸»å¯¼å‹ä½ç½®**: ç›´æ¥è°ƒæ•´é…ç½®å€¼ï¼Œæ•ˆæœç«‹ç«¿è§å½±")
        report.append("2. **ä¸­ä»‹ä¸»å¯¼å‹ä½ç½®**: å…³æ³¨ä¸­ä»‹å˜é‡å˜åŒ–ï¼Œé€šè¿‡é—´æ¥è·¯å¾„ä¼˜åŒ–")
        report.append("3. **æ··åˆå½±å“å‹ä½ç½®**: ç»¼åˆè€ƒè™‘ç›´æ¥å’Œé—´æ¥æ•ˆåº”ï¼Œå…¨é¢è¯„ä¼°è°ƒæ•´å½±å“")
        report.append("4. **æœºåˆ¶éªŒè¯**: å»ºè®®é€šè¿‡A/Bæµ‹è¯•éªŒè¯è¯†åˆ«å‡ºçš„å½±å“æœºåˆ¶")
        report.append("")

    def _add_key_findings_and_recommendations(self, report):
        report.append("\n## ğŸ’¡ å…³é”®å‘ç°ä¸å»ºè®®\n")
        report.append("### ğŸ“ ç»“æœè§£è¯»è¯´æ˜")
        report.append("- **ä½ç½®é‡è¦æ€§æ’åº**: åŸºäºå„ä½ç½®å¯¹ä¸»è¦æŒ‡æ ‡çš„å¹³å‡ç»å¯¹ç›¸å…³æ€§æ’åº")
        report.append("- **äº¤äº’æ•ˆåº”å¼ºåº¦**: è¡¡é‡ä½ç½®é—´ååŒæˆ–å†²çªçš„ç¨‹åº¦ï¼Œç»å¯¹å€¼è¶Šå¤§å½±å“è¶Šæ˜æ˜¾")
        report.append("- **ä¸­ä»‹æ•ˆåº”**: åˆ†æä½ç½®é€šè¿‡å…¶ä»–æŒ‡æ ‡é—´æ¥å½±å“ç›®æ ‡æŒ‡æ ‡çš„è·¯å¾„")
        report.append("- **é…ç½®å»ºè®®**: åŸºäºç»Ÿè®¡åˆ†æç»“æœæä¾›çš„ä¼˜åŒ–æ–¹å‘ï¼Œéœ€ç»“åˆå®é™…æ¸¸æˆä½“éªŒéªŒè¯\n")

        # ä½ç½®é‡è¦æ€§æ’åº
        if 'correlations' in self.results:
            pos_importance = {}
            for pos in ['pos1', 'pos2', 'pos3']:
                avg_abs_corr = np.mean([
                    abs(self.results['correlations']['position_correlations'][pos][m]['correlation'])
                    for m in ['DifficultyScore', 'PeakDockCount', 'PressureValueMean']
                    if m in self.results['correlations']['position_correlations'][pos]
                ])
                pos_importance[pos] = avg_abs_corr

            sorted_positions = sorted(pos_importance.items(), key=lambda x: x[1], reverse=True)
            report.append("### ä¸»è¦å‘ç°:")
            report.append(f"1. **ä½ç½®é‡è¦æ€§æ’åº**: {' > '.join([f'{p}({v:.3f})' for p, v in sorted_positions])}")

        # å…³é”®äº¤äº’æ•ˆåº”
        if 'interaction_effects' in self.results:
            max_interaction = None
            max_strength = 0
            for pair, effects in self.results['interaction_effects'].items():
                for metric, data in effects.items():
                    if data['interaction_strength'] > max_strength:
                        max_strength = data['interaction_strength']
                        max_interaction = f"{pair}->{metric}"
            if max_interaction:
                report.append(f"2. **æœ€å…³é”®äº¤äº’æ•ˆåº”**: {max_interaction} (strength: {max_strength:.3f})")

        report.append("\n### ä¼˜åŒ–å»ºè®®:")
        report.append("1. é‡ç‚¹å…³æ³¨å½±å“åŠ›æœ€å¤§çš„ä½ç½®å‚æ•°")
        report.append("2. è€ƒè™‘ä½ç½®é—´çš„äº¤äº’æ•ˆåº”ï¼Œé¿å…å•çº¯çš„ç‹¬ç«‹è°ƒæ•´")
        report.append("3. æ ¹æ®ä¸­ä»‹æœºåˆ¶é’ˆå¯¹æ€§ä¼˜åŒ–ï¼Œæé«˜è°ƒæ•´ç²¾åº¦")
        report.append("4. **DifficultyPositionä¼˜åŒ–å»ºè®®**ï¼š")
        report.append("   - **ç†æƒ³èŒƒå›´**: 0.4-0.7ï¼ˆä¸­æœŸéš¾ç‚¹ï¼‰ï¼Œæä¾›è‰¯å¥½çš„æŒ‘æˆ˜èŠ‚å¥")
        report.append("   - **é¿å…**: 0-0.3ï¼ˆå‰æœŸéš¾ç‚¹ï¼‰ï¼Œå®¹æ˜“é€ æˆå¼€å±€æŒ«è´¥")
        report.append("   - **å¯æ¥å—**: 0.7-0.99ï¼ˆåæœŸéš¾ç‚¹ï¼‰ï¼Œæ¸è¿›å¼æŒ‘æˆ˜")
        report.append("   - **ç‰¹æ®Šæƒ…å†µ**: DifficultyPosition=1ï¼ˆæ— æ˜æ˜¾éš¾ç‚¹ï¼‰é€‚åˆä¼‘é—²ä½“éªŒ")
        report.append("5. å»ºè®®ç»“åˆA/Bæµ‹è¯•éªŒè¯ç»Ÿè®¡åˆ†æç»“æœ")

        report.append("\n### âš ï¸ æ³¨æ„äº‹é¡¹:")
        report.append("- æœ¬åˆ†æåŸºäºå†å²æ•°æ®ï¼Œç»“æœéœ€è¦åœ¨å®é™…ç¯å¢ƒä¸­éªŒè¯")
        report.append("- ç»Ÿè®¡æ˜¾è‘—æ€§ä¸ç­‰äºå®é™…æ˜¾è‘—æ€§ï¼Œéœ€è¦ç»“åˆæ¸¸æˆè®¾è®¡ç›®æ ‡åˆ¤æ–­")
        report.append("- é…ç½®è°ƒæ•´åº”è¯¥æ¸è¿›å¼è¿›è¡Œï¼Œé¿å…å¤§å¹…å˜åŠ¨å½±å“ç©å®¶ä½“éªŒ")
        report.append("- å»ºè®®å®šæœŸé‡æ–°åˆ†æä»¥é€‚åº”æ¸¸æˆå‘å±•å’Œç©å®¶è¡Œä¸ºå˜åŒ–")

    def _add_value_specific_report(self, report):
        """åˆ é™¤æ•°å€¼ç‰¹å¼‚æ€§åˆ†æ - å·²ç§»é™¤"""
        pass

    def _add_gradient_effects_report(self, report):
        """æ·»åŠ æ•°å€¼æ¢¯åº¦æ•ˆåº”æŠ¥å‘Š"""
        if 'gradient_effects' not in self.results:
            return

        report.append("\n## ğŸ“ˆ æ•°å€¼æ¢¯åº¦æ•ˆåº”åˆ†æ\n")
        report.append("### ğŸ“ æ¢¯åº¦æ•ˆåº”åˆ†æè¯´æ˜")
        report.append("**æ•°å€¼æ¢¯åº¦æ•ˆåº”åˆ†æ** ç ”ç©¶ä½“éªŒé…ç½®æ•°å€¼ä»ä½åˆ°é«˜å˜åŒ–æ—¶å¯¹æ¸¸æˆæŒ‡æ ‡äº§ç”Ÿçš„æ¸è¿›æ€§å½±å“ã€‚")
        report.append("é€šè¿‡åˆ†ææ•°å€¼å˜åŒ–çš„è¶‹åŠ¿å’Œæ¨¡å¼ï¼Œè¯†åˆ«é…ç½®çš„æ•æ„ŸåŒºé—´å’Œæœ€ä¼˜å–å€¼èŒƒå›´ã€‚")
        report.append("")
        report.append("**æ ¸å¿ƒæ¦‚å¿µï¼š**")
        report.append("- **æ¢¯åº¦æ–œç‡**: æ•°å€¼æ¯å¢åŠ 1ä¸ªå•ä½æ—¶æŒ‡æ ‡çš„å¹³å‡å˜åŒ–é‡")
        report.append("- **æ•æ„ŸåŒºé—´**: æ¢¯åº¦å˜åŒ–å‰§çƒˆçš„æ•°å€¼èŒƒå›´ï¼Œå°å¹…è°ƒæ•´äº§ç”Ÿæ˜¾è‘—å½±å“")
        report.append("- **å¹³ç¨³åŒºé—´**: æ¢¯åº¦å˜åŒ–å¹³ç¼“çš„æ•°å€¼èŒƒå›´ï¼Œè°ƒæ•´å½±å“ç›¸å¯¹ç¨³å®š")
        report.append("- **æ‹ç‚¹**: æ¢¯åº¦æ–¹å‘å‘ç”Ÿæ˜æ˜¾å˜åŒ–çš„å…³é”®æ•°å€¼ç‚¹")
        report.append("")
        report.append("**åˆ†æä»·å€¼ï¼š**")
        report.append("- **ç²¾ç¡®è°ƒä¼˜**: è¯†åˆ«æ•°å€¼è°ƒæ•´çš„æœ€ä½³æ–¹å‘å’Œå¹…åº¦")
        report.append("- **é£é™©æ§åˆ¶**: é¿å…åœ¨æ•æ„ŸåŒºé—´è¿›è¡Œå¤§å¹…è°ƒæ•´")
        report.append("- **æ•ˆæœé¢„æµ‹**: åŸºäºæ¢¯åº¦è¶‹åŠ¿é¢„æµ‹æ•°å€¼å˜åŒ–çš„å½±å“")
        report.append("")

        for pos in ['pos1', 'pos2', 'pos3']:
            if pos in self.results['gradient_effects']:
                report.append(f"### {pos}æ¢¯åº¦æ•ˆåº”:")
                pos_gradients = self.results['gradient_effects'][pos]

                for metric in ['DifficultyScore', 'PeakDockCount', 'PressureValueMean']:
                    if metric in pos_gradients:
                        gradient_data = pos_gradients[metric]
                        critical_point = gradient_data['critical_point']
                        max_gradient = gradient_data['max_gradient']
                        avg_gradient = gradient_data['avg_gradient']

                        report.append(f"- **{metric}æ¢¯åº¦**: å¹³å‡æ¢¯åº¦{avg_gradient:.3f}, æœ€å¤§æ¢¯åº¦{max_gradient:.3f}")
                        if critical_point:
                            report.append(f"  - å…³é”®è½¬æŠ˜ç‚¹: æ•°å€¼{critical_point}")

                report.append("")

    def _add_dock_sequence_report(self, report):
        """åˆ é™¤Dockåºåˆ—æ·±åº¦åˆ†æ - å·²ç§»é™¤"""
        pass

    def _add_pressure_dynamics_report(self, report):
        """æ·»åŠ å‹åŠ›åŠ¨æ€åˆ†ææŠ¥å‘Š"""
        if 'pressure_dynamics' not in self.results:
            return

        report.append("\n## âš¡ å‹åŠ›åŠ¨æ€åˆ†æ\n")

        pressure_names = {
            'PressureValueMean': 'å¹³å‡å‹åŠ›',
            'PressureValueMax': 'å³°å€¼å‹åŠ›',
            'PressureValueStdDev': 'å‹åŠ›æ³¢åŠ¨'
        }

        for pos in ['pos1', 'pos2', 'pos3']:
            if pos in self.results['pressure_dynamics']:
                report.append(f"### {pos}å‹åŠ›åŠ¨æ€:")
                pos_data = self.results['pressure_dynamics'][pos]

                # åˆ†ææ¯ç§å‹åŠ›ç±»å‹
                for pressure_type, pressure_name in pressure_names.items():
                    report.append(f"#### {pressure_name}:")

                    # æ‰¾å‡ºæå€¼é…ç½®
                    min_pressure_config = None
                    max_pressure_config = None
                    min_pressure = float('inf')
                    max_pressure = 0

                    for value in range(1, 10):
                        value_key = f'value_{value}'
                        if (value_key in pos_data and
                            pressure_type in pos_data[value_key] and
                            'statistics' in pos_data[value_key][pressure_type]):

                            stats = pos_data[value_key][pressure_type]['statistics']
                            mean_pressure = stats['mean']

                            if mean_pressure < min_pressure:
                                min_pressure = mean_pressure
                                min_pressure_config = value
                            if mean_pressure > max_pressure:
                                max_pressure = mean_pressure
                                max_pressure_config = value

                    if min_pressure_config:
                        report.append(f"- **æœ€ä½å‹åŠ›**: æ•°å€¼{min_pressure_config}, {pressure_name}{min_pressure:.3f}")
                    if max_pressure_config:
                        report.append(f"- **æœ€é«˜å‹åŠ›**: æ•°å€¼{max_pressure_config}, {pressure_name}{max_pressure:.3f}")

                report.append("")

    def _print_key_findings(self):
        """è¾“å‡ºå…³é”®å‘ç°æ‘˜è¦"""
        print("\nğŸ’¡ === å…³é”®å‘ç°æ‘˜è¦ ===")

        # ä½ç½®é‡è¦æ€§æ’åº
        if 'correlations' in self.results:
            pos_importance = {}
            for pos in ['pos1', 'pos2', 'pos3']:
                avg_abs_corr = np.mean([
                    abs(self.results['correlations']['position_correlations'][pos][m]['correlation'])
                    for m in ['DifficultyScore', 'PeakDockCount', 'PressureValueMean']
                    if m in self.results['correlations']['position_correlations'][pos]
                ])
                pos_importance[pos] = avg_abs_corr

            sorted_positions = sorted(pos_importance.items(), key=lambda x: x[1], reverse=True)
            print(f"ğŸ¯ ä½ç½®é‡è¦æ€§æ’åº: {' > '.join([f'{p}({v:.3f})' for p, v in sorted_positions])}")

        # æœ€å¼ºäº¤äº’æ•ˆåº”
        if 'interaction_effects' in self.results:
            max_interaction = None
            max_strength = 0
            for pair, effects in self.results['interaction_effects'].items():
                for metric, data in effects.items():
                    if data['interaction_strength'] > max_strength:
                        max_strength = data['interaction_strength']
                        max_interaction = f"{pair}->{metric}"
            if max_interaction:
                print(f"ğŸ”„ æœ€å¼ºäº¤äº’æ•ˆåº”: {max_interaction} (strength: {max_strength:.3f})")

        # æœ€å…³é”®ä¸­ä»‹è·¯å¾„
        if 'mechanism_effects' in self.results:
            strongest_mediation = None
            max_mediation_strength = 0
            for pos, mechanism in self.results['mechanism_effects'].items():
                if 'strongest_mediation_path' in mechanism:
                    strength = abs(mechanism['strongest_mediation_path']['strength'])
                    if strength > max_mediation_strength:
                        max_mediation_strength = strength
                        strongest_mediation = f"{pos}->{mechanism['strongest_mediation_path']['mediator']}->DifficultyScore"
            if strongest_mediation:
                print(f"ğŸ” æœ€å…³é”®ä¸­ä»‹è·¯å¾„: {strongest_mediation} (strength: {max_mediation_strength:.3f})")

    # åŸºç¡€å¯è§†åŒ–æ–¹æ³•ï¼ˆç®€åŒ–ç‰ˆå®ç°ï¼‰
    def _plot_position_correlation_heatmap(self, output_path: Path):
        """ç»˜åˆ¶ä½ç½®ç›¸å…³æ€§çƒ­åŠ›å›¾"""
        if 'correlations' not in self.results:
            return

        fig, ax = plt.subplots(figsize=(10, 8))

        # æ„å»ºç›¸å…³æ€§çŸ©é˜µ
        positions = ['pos1', 'pos2', 'pos3']
        metrics = ['DifficultyScore', 'PeakDockCount', 'PressureValueMean']
        corr_matrix = []

        for pos in positions:
            pos_corrs = []
            for metric in metrics:
                if pos in self.results['correlations']['position_correlations'] and \
                   metric in self.results['correlations']['position_correlations'][pos]:
                    corr = self.results['correlations']['position_correlations'][pos][metric]['correlation']
                    pos_corrs.append(corr)
                else:
                    pos_corrs.append(0)
            corr_matrix.append(pos_corrs)

        corr_matrix = np.array(corr_matrix)

        # ç»˜åˆ¶çƒ­åŠ›å›¾
        im = ax.imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1, aspect='auto')

        # è®¾ç½®æ ‡ç­¾
        ax.set_xticks(range(len(metrics)))
        ax.set_xticklabels(metrics, rotation=45, ha='right')
        ax.set_yticks(range(len(positions)))
        ax.set_yticklabels(positions)

        # æ·»åŠ é¢œè‰²æ¡
        plt.colorbar(im, ax=ax, label='ç›¸å…³ç³»æ•°')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i in range(len(positions)):
            for j in range(len(metrics)):
                ax.text(j, i, f'{corr_matrix[i, j]:.3f}',
                       ha='center', va='center', color='white' if abs(corr_matrix[i, j]) > 0.5 else 'black')

        plt.title('Position-Metric Correlation Heatmap')
        plt.tight_layout()
        plt.savefig(output_path / 'position_correlation_heatmap.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_pattern_boxplots(self, output_path: Path):
        """ç»˜åˆ¶é…ç½®æ¨¡å¼ç®±çº¿å›¾"""
        if 'patterns' not in self.results:
            return

        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        patterns = self.results['patterns']['sequence_patterns']

        metrics = ['DifficultyScore', 'PeakDockCount', 'PressureValueMean']

        for idx, metric in enumerate(metrics):
            ax = axes[idx//2, idx%2]
            pattern_names = []
            pattern_means = []
            pattern_stds = []

            for pattern_name, pattern_data in patterns.items():
                if metric in pattern_data and 'mean' in pattern_data[metric]:
                    pattern_names.append(pattern_name)
                    pattern_means.append(pattern_data[metric]['mean'])
                    pattern_stds.append(pattern_data[metric].get('std', 0))

            if pattern_names:
                bars = ax.bar(pattern_names, pattern_means, yerr=pattern_stds, alpha=0.7, capsize=5)
                ax.set_title(f'{metric} Configuration Pattern Comparison')
                ax.set_ylabel(metric)
                ax.tick_params(axis='x', rotation=45)

                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for bar, mean in zip(bars, pattern_means):
                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + bar.get_height()*0.01,
                           f'{mean:.2f}', ha='center', va='bottom')

        plt.suptitle('é…ç½®æ¨¡å¼åˆ†æç®±çº¿å›¾')
        plt.tight_layout()
        plt.savefig(output_path / 'pattern_boxplots.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_feature_importance(self, output_path: Path):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾"""
        if 'models' not in self.results:
            return

        key_metrics = ['DifficultyScore', 'PeakDockCount', 'PressureValueMean']
        fig, axes = plt.subplots(1, len(key_metrics), figsize=(18, 6))

        for i, metric in enumerate(key_metrics):
            if metric in self.results['models']:
                importance = self.results['models'][metric]['feature_importance']

                # å–å‰8ä¸ªé‡è¦ç‰¹å¾
                top_features = dict(sorted(importance.items(), key=lambda x: x[1], reverse=True)[:8])

                features = list(top_features.keys())
                values = list(top_features.values())

                bars = axes[i].barh(features, values, alpha=0.7)
                axes[i].set_title(f'{metric}\nFeature Importance (RÂ²={self.results["models"][metric]["r2_score"]:.3f})')
                axes[i].set_xlabel('Importance Score')

                # é¢œè‰²æ˜ å°„
                colors = plt.cm.viridis(np.linspace(0, 1, len(values)))
                for bar, color in zip(bars, colors):
                    bar.set_color(color)

        plt.suptitle('æœºå™¨å­¦ä¹ æ¨¡å‹ç‰¹å¾é‡è¦æ€§åˆ†æ')
        plt.tight_layout()
        plt.savefig(output_path / 'feature_importance.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_config_distribution(self, output_path: Path):
        """ç»˜åˆ¶é…ç½®åˆ†å¸ƒæ•£ç‚¹å›¾ï¼Œå¢åŠ æ•°å€¼å®‰å…¨æ£€æŸ¥"""
        try:
            # æ£€æŸ¥å¿…è¦æ•°æ®
            if len(self.features) == 0 or len(self.data) == 0:
                print("   âš ï¸ æ— é…ç½®åˆ†å¸ƒæ•°æ®ï¼Œè·³è¿‡ç»˜åˆ¶")
                return

            fig, axes = plt.subplots(2, 2, figsize=(15, 12))

            # 3Dé…ç½®ç©ºé—´æŠ•å½± (pos1 vs pos2ï¼Œé¢œè‰²è¡¨ç¤ºpos3)
            pos1_vals = self.features['pos1'].values
            pos2_vals = self.features['pos2'].values
            pos3_vals = self.features['pos3'].values

            # æ•°å€¼èŒƒå›´æ£€æŸ¥
            if np.any(~np.isfinite(pos1_vals)) or np.any(~np.isfinite(pos2_vals)) or np.any(~np.isfinite(pos3_vals)):
                print("   âš ï¸ é…ç½®æ•°æ®åŒ…å«æ— æ•ˆå€¼ï¼Œä½¿ç”¨æœ‰æ•ˆå­é›†")
                valid_mask = np.isfinite(pos1_vals) & np.isfinite(pos2_vals) & np.isfinite(pos3_vals)
                pos1_vals = pos1_vals[valid_mask]
                pos2_vals = pos2_vals[valid_mask]
                pos3_vals = pos3_vals[valid_mask]

            if len(pos1_vals) > 0:
                scatter = axes[0,0].scatter(pos1_vals, pos2_vals, c=pos3_vals,
                                          cmap='viridis', alpha=0.6, s=1)
                axes[0,0].set_xlabel('Position 1 Value')
                axes[0,0].set_ylabel('Position 2 Value')
                axes[0,0].set_title('Configuration Space Distribution (Color=pos3)')
                plt.colorbar(scatter, ax=axes[0,0], label='pos3 Value')

            # é…ç½®ä¸DifficultyScoreçš„å…³ç³»
            if 'DifficultyScore' in self.data.columns:
                config_sum = self.features['config_sum'].values
                difficulty = self.data['DifficultyScore'].values

                # è¿‡æ»¤æ— æ•ˆå€¼
                valid_mask = np.isfinite(config_sum) & np.isfinite(difficulty)
                if np.any(valid_mask):
                    axes[0,1].scatter(config_sum[valid_mask], difficulty[valid_mask], alpha=0.3, s=1)
                    axes[0,1].set_xlabel('Configuration Sum')
                    axes[0,1].set_ylabel('DifficultyScore')
                    axes[0,1].set_title('Configuration Sum vs Difficulty Score')

            # é…ç½®æ ‡å‡†å·®åˆ†å¸ƒ
            config_std = self.features['config_std'].values
            valid_std = config_std[np.isfinite(config_std)]
            if len(valid_std) > 0:
                axes[1,0].hist(valid_std, bins=min(30, len(valid_std)//10), alpha=0.7, edgecolor='black')
                axes[1,0].set_xlabel('Configuration Standard Deviation')
                axes[1,0].set_ylabel('Frequency')
                axes[1,0].set_title('Configuration Standard Deviation Distribution')

            # æå€¼é…ç½®æ•ˆåº”åˆ†æ
            if 'DifficultyScore' in self.data.columns:
                extreme_low = self.data[self.features['has_extreme_low'] == 1]
                extreme_high = self.data[self.features['has_extreme_high'] == 1]
                normal = self.data[(self.features['has_extreme_low'] == 0) & (self.features['has_extreme_high'] == 0)]

                if len(extreme_low) > 0 and len(extreme_high) > 0 and len(normal) > 0:
                    means = []
                    categories = []

                    for name, group in [('æä½é…ç½®', extreme_low), ('æ­£å¸¸é…ç½®', normal), ('æé«˜é…ç½®', extreme_high)]:
                        difficulty_vals = group['DifficultyScore'].values
                        valid_vals = difficulty_vals[np.isfinite(difficulty_vals)]
                        if len(valid_vals) > 0:
                            categories.append(name)
                            means.append(np.mean(valid_vals))

                    if means:
                        colors = ['red', 'gray', 'blue'][:len(means)]
                        bars = axes[1,1].bar(categories, means, alpha=0.7, color=colors)
                        axes[1,1].set_ylabel('Average DifficultyScore')
                        axes[1,1].set_title('Extreme Configuration Effect Analysis')

                        # æ·»åŠ æ•°å€¼æ ‡ç­¾
                        for bar, mean in zip(bars, means):
                            if np.isfinite(mean):
                                axes[1,1].text(bar.get_x() + bar.get_width()/2,
                                              bar.get_height() + bar.get_height()*0.01,
                                              f'{mean:.2f}', ha='center', va='bottom')

            plt.suptitle('ä½“éªŒé…ç½®åˆ†å¸ƒç‰¹å¾åˆ†æ')
            plt.tight_layout()
            plt.savefig(output_path / 'config_distribution.png', dpi=300, bbox_inches='tight')
            plt.close()

        except Exception as e:
            print(f"   âŒ é…ç½®åˆ†å¸ƒå›¾ç»˜åˆ¶é”™è¯¯: {str(e)}")
            plt.close('all')

    def _plot_model_performance(self, output_path: Path):
        """ç»˜åˆ¶æ¨¡å‹æ€§èƒ½å›¾"""
        if 'models' not in self.results:
            return

        metrics = list(self.results['models'].keys())
        r2_scores = [self.results['models'][m]['r2_score'] for m in metrics]
        rmse_scores = [self.results['models'][m]['rmse'] for m in metrics]

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

        # RÂ²åˆ†æ•°
        bars1 = ax1.bar(metrics, r2_scores, color='skyblue', alpha=0.7)
        ax1.set_title('Prediction Model RÂ² Performance Score')
        ax1.set_ylabel('RÂ² Score')
        ax1.tick_params(axis='x', rotation=45)
        ax1.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Baseline(0.5)')
        ax1.legend()

        # ä¸ºæ¯ä¸ªbaræ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, score in zip(bars1, r2_scores):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{score:.3f}', ha='center', va='bottom')

        # RMSEåˆ†æ•°
        bars2 = ax2.bar(metrics, rmse_scores, color='lightcoral', alpha=0.7)
        ax2.set_title('Prediction Model RMSE Error')
        ax2.set_ylabel('RMSE')
        ax2.tick_params(axis='x', rotation=45)

        plt.suptitle('Machine Learning Model Performance Evaluation')
        plt.tight_layout()
        plt.savefig(output_path / 'model_performance.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_value_impact_heatmaps(self, output_path: Path):
        """ç»˜åˆ¶æ•°å€¼å½±å“çŸ©é˜µçƒ­åŠ›å›¾ - 9Ã—3çŸ©é˜µæ˜¾ç¤ºæ¯ä¸ªæ•°å€¼åœ¨æ¯ä¸ªä½ç½®çš„å½±å“"""
        if 'value_specific_effects' not in self.results:
            return

        fig, axes = plt.subplots(1, 3, figsize=(18, 8))

        # ä¸ºæ¯ä¸ªæŒ‡æ ‡åˆ›å»ºçƒ­åŠ›å›¾
        metrics = ['DifficultyScore', 'success_rate', 'PressureValueMean']
        metric_names = ['éš¾åº¦åˆ†æ•°', 'èƒœç‡', 'å¹³å‡å‹åŠ›']

        for idx, (metric_key, metric_name) in enumerate(zip(metrics, metric_names)):
            # æ„å»º9x3çŸ©é˜µ
            matrix = np.zeros((9, 3))

            for value in range(1, 10):
                value_key = f"value_{value}"
                if value_key in self.results['value_specific_effects']:
                    for pos_idx, pos in enumerate(['pos1', 'pos2', 'pos3']):
                        if pos in self.results['value_specific_effects'][value_key]:
                            pos_data = self.results['value_specific_effects'][value_key][pos]

                            if metric_key == 'DifficultyScore' and 'difficulty_impact' in pos_data:
                                matrix[value-1, pos_idx] = pos_data['difficulty_impact']['mean']
                            elif metric_key == 'success_rate' and 'win_rate' in pos_data:
                                matrix[value-1, pos_idx] = pos_data['win_rate']['success_rate']
                            elif metric_key == 'PressureValueMean' and 'pressure_impact' in pos_data:
                                pressure_data = pos_data['pressure_impact']
                                if 'PressureValueMean' in pressure_data:
                                    matrix[value-1, pos_idx] = pressure_data['PressureValueMean']['mean']

            # ç»˜åˆ¶çƒ­åŠ›å›¾
            im = axes[idx].imshow(matrix, aspect='auto', cmap='RdYlBu_r')

            # è®¾ç½®æ ‡ç­¾
            axes[idx].set_xticks(range(3))
            axes[idx].set_xticklabels(['Position1', 'Position2', 'Position3'])
            axes[idx].set_yticks(range(9))
            axes[idx].set_yticklabels([f'Value{i}' for i in range(1, 10)])
            axes[idx].set_title(f'{metric_name} Impact Matrix')

            # æ·»åŠ é¢œè‰²æ¡
            plt.colorbar(im, ax=axes[idx])

        plt.suptitle('æ•°å€¼-ä½ç½®å½±å“çŸ©é˜µçƒ­åŠ›å›¾', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(output_path / 'value_impact_heatmaps.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_gradient_curves(self, output_path: Path):
        """ç»˜åˆ¶æ•°å€¼æ¢¯åº¦æ•ˆåº”æ›²çº¿"""
        if 'gradient_effects' not in self.results:
            return

        fig, axes = plt.subplots(1, 3, figsize=(18, 6))

        for idx, pos in enumerate(['pos1', 'pos2', 'pos3']):
            if pos in self.results['gradient_effects']:
                pos_gradients = self.results['gradient_effects'][pos]

                for metric in ['DifficultyScore', 'PeakDockCount', 'PressureValueMean']:
                    if metric in pos_gradients:
                        data = pos_gradients[metric]
                        value_means = data['value_means']
                        critical_point = data['critical_point']

                        # è¿‡æ»¤æ‰nanå€¼
                        valid_indices = [i for i, val in enumerate(value_means) if not np.isnan(val)]
                        valid_values = [i+1 for i in valid_indices]
                        valid_means = [value_means[i] for i in valid_indices]

                        if len(valid_values) > 2:
                            axes[idx].plot(valid_values, valid_means, 'o-', label=metric, linewidth=2, markersize=6)

                            # æ ‡è®°ä¸´ç•Œç‚¹
                            if critical_point and critical_point in valid_values:
                                critical_idx = valid_values.index(critical_point)
                                axes[idx].scatter([critical_point], [valid_means[critical_idx]],
                                                s=100, c='red', marker='*', zorder=5)

                axes[idx].set_xlabel('Configuration Value')
                axes[idx].set_ylabel('Metric Mean')
                axes[idx].set_title(f'{pos} Gradient Effect Curve')
                axes[idx].legend()
                axes[idx].grid(True, alpha=0.3)

        plt.suptitle('Value Gradient Effect Analysis Curves', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(output_path / 'gradient_curves.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_difficulty_position_analysis(self, output_path: Path):
        """ç»˜åˆ¶DifficultyPositionå½±å“åˆ†æå›¾"""
        if 'difficulty_position_effects' not in self.results:
            return

        fig, axes = plt.subplots(2, 3, figsize=(18, 12))

        # ä¸Šæ’ï¼šæ¯ä¸ªä½ç½®å¯¹DifficultyPositionçš„å½±å“
        for i, pos in enumerate(['pos1', 'pos2', 'pos3']):
            if pos in self.results['difficulty_position_effects']:
                pos_data = self.results['difficulty_position_effects'][pos]

                if 'value_effects' in pos_data and pos_data['value_effects']:
                    values = list(pos_data['value_effects'].keys())
                    means = [pos_data['value_effects'][v]['mean'] for v in values]
                    stds = [pos_data['value_effects'][v]['std'] for v in values]

                    bars = axes[0, i].bar(values, means, yerr=stds, alpha=0.7, capsize=5)
                    axes[0, i].set_xlabel(f'{pos} Value')
                    axes[0, i].set_ylabel('DifficultyPosition Average')
                    axes[0, i].set_title(f'{pos} Effect on DifficultyPosition')
                    axes[0, i].grid(True, alpha=0.3)

                    # æ·»åŠ æ•°å€¼æ ‡ç­¾
                    for bar, mean in zip(bars, means):
                        axes[0, i].text(bar.get_x() + bar.get_width()/2,
                                       bar.get_height() + bar.get_height()*0.01,
                                       f'{mean:.2f}', ha='center', va='bottom', fontsize=8)

        # ä¸‹æ’ï¼šäº¤äº’æ•ˆåº”åˆ†æ
        if 'interaction_effects' in self.results['difficulty_position_effects']:
            interaction_data = self.results['difficulty_position_effects']['interaction_effects']

            if interaction_data:
                pairs = list(interaction_data.keys())
                gains = [interaction_data[pair]['interaction_gain'] for pair in pairs]

                # åˆå¹¶ä¸‹æ’ä¸‰ä¸ªå­å›¾ä¸ºä¸€ä¸ªå¤§å›¾
                ax_combined = plt.subplot(2, 1, 2)
                bars = ax_combined.bar(pairs, gains, alpha=0.7,
                                     color=['red' if g > 0 else 'blue' for g in gains])
                ax_combined.set_xlabel('Position Combination')
                ax_combined.set_ylabel('Interaction Effect Gain')
                ax_combined.set_title('DifficultyPosition Interaction Effect Analysis')
                ax_combined.axhline(y=0, color='black', linestyle='--', alpha=0.5)
                ax_combined.grid(True, alpha=0.3)

                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for bar, gain in zip(bars, gains):
                    ax_combined.text(bar.get_x() + bar.get_width()/2,
                                   bar.get_height() + (0.01 if gain > 0 else -0.03),
                                   f'{gain:.4f}', ha='center',
                                   va='bottom' if gain > 0 else 'top', fontsize=9)

                # éšè—ä¸‹æ’åŸæœ‰çš„ä¸‰ä¸ªå­å›¾
                for i in range(3):
                    axes[1, i].set_visible(False)

        plt.suptitle('DifficultyPositionä½ç½®å½±å“åˆ†æ', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(output_path / 'difficulty_position_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_dock_sequence_patterns(self, output_path: Path):
        """ç»˜åˆ¶Dockåºåˆ—æ¨¡å¼å›¾"""
        if 'dock_deep_analysis' not in self.results:
            return

        fig, axes = plt.subplots(1, 3, figsize=(18, 6))

        # ä¸ºæ¯ä¸ªä½ç½®ç»˜åˆ¶ä¸åŒæ•°å€¼çš„æˆåŠŸç‡åˆ†æ
        colors = plt.cm.Set3(np.linspace(0, 1, 9))

        for pos_idx, pos in enumerate(['pos1', 'pos2', 'pos3']):
            if pos in self.results['dock_deep_analysis']:
                pos_data = self.results['dock_deep_analysis'][pos]

                # æˆåŠŸç‡åˆ†æ
                success_rates = []
                values = []

                for value in range(1, 10):
                    value_key = f'value_{value}'
                    if value_key in pos_data:
                        success_rates.append(pos_data[value_key]['success_rate'])
                        values.append(value)

                if success_rates:
                    bars = axes[pos_idx].bar(values, success_rates, color=colors[:len(values)], alpha=0.7)
                    axes[pos_idx].set_xlabel('Configuration Value')
                    axes[pos_idx].set_ylabel('Success Rate')
                    axes[pos_idx].set_title(f'{pos} - Win Rate Performance')
                    axes[pos_idx].set_ylim(0, 1)

                    # æ·»åŠ æ•°å€¼æ ‡ç­¾
                    for bar, rate in zip(bars, success_rates):
                        axes[pos_idx].text(bar.get_x() + bar.get_width()/2,
                                          bar.get_height() + 0.02,
                                          f'{rate:.3f}', ha='center', va='bottom')

        plt.suptitle('Dockåºåˆ—æ¨¡å¼ä¸æˆåŠŸç‡åˆ†æ', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(output_path / 'dock_sequence_patterns.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_pressure_dynamics(self, output_path: Path):
        """ç»˜åˆ¶å‹åŠ›åŠ¨æ€åˆ†å¸ƒå›¾"""
        if 'pressure_dynamics' not in self.results:
            return

        fig, axes = plt.subplots(3, 3, figsize=(18, 15))

        pressure_types = ['PressureValueMean', 'PressureValueMax', 'PressureValueStdDev']
        pressure_names = ['å¹³å‡å‹åŠ›', 'æœ€å¤§å‹åŠ›', 'å‹åŠ›æ³¢åŠ¨']

        for row, (pressure_type, pressure_name) in enumerate(zip(pressure_types, pressure_names)):
            for col, pos in enumerate(['pos1', 'pos2', 'pos3']):
                if pos in self.results['pressure_dynamics']:
                    pos_data = self.results['pressure_dynamics'][pos]

                    # æ”¶é›†æ•°æ®
                    values = []
                    means = []
                    q95s = []

                    for value in range(1, 10):
                        value_key = f'value_{value}'
                        if (value_key in pos_data and
                            pressure_type in pos_data[value_key] and
                            'statistics' in pos_data[value_key][pressure_type]):

                            stats = pos_data[value_key][pressure_type]['statistics']
                            values.append(value)
                            means.append(stats['mean'])
                            q95s.append(stats['q95'])

                    if values:
                        # ç»˜åˆ¶å¹³å‡å€¼çº¿
                        axes[row, col].plot(values, means, 'o-', label='Mean', linewidth=2, markersize=6)

                        # ç»˜åˆ¶95%åˆ†ä½æ•°çº¿
                        axes[row, col].plot(values, q95s, 's--', label='95% Percentile', alpha=0.7)

                        axes[row, col].set_xlabel('Configuration Value')
                        axes[row, col].set_ylabel(pressure_name)
                        axes[row, col].set_title(f'{pos} - {pressure_name} Dynamics')
                        axes[row, col].legend()
                        axes[row, col].grid(True, alpha=0.3)

        plt.suptitle('Pressure Metric Dynamics Analysis', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(output_path / 'pressure_dynamics.png', dpi=300, bbox_inches='tight')
        plt.close()

    def create_visualizations(self, output_dir: str = None):
        """å…¼å®¹æ–¹æ³•ï¼šåˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        self.create_enhanced_visualizations(output_dir)

    def generate_report(self, output_path: str = None) -> str:
        """å…¼å®¹æ–¹æ³•ï¼šç”ŸæˆåŸºç¡€åˆ†ææŠ¥å‘Š"""
        return self.generate_enhanced_report(output_path)


def main():
    """ä¸»å‡½æ•° - è¿è¡Œæ·±åº¦åˆ†æ"""
    import sys
    import os

    # è®¾ç½®UTF-8ç¼–ç è¾“å‡º
    if sys.platform.startswith('win'):
        os.system('chcp 65001 >nul 2>&1')
        # è®¾ç½®æ§åˆ¶å°è¾“å‡ºç¼–ç 
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

    print("ğŸš€ ä½“éªŒæ¨¡å¼é…ç½®æ·±åº¦å½±å“åˆ†æå·¥å…·å¯åŠ¨...", flush=True)

    try:
        # åˆ›å»ºåˆ†æå™¨å®ä¾‹ - é»˜è®¤ä½¿ç”¨å¤šæ–‡ä»¶æ¨¡å¼
        analyzer = ExperienceConfigAnalyzer()

        # è¿è¡Œæ·±åº¦åˆ†æ
        results = analyzer.run_complete_analysis()

        print(f"\nâœ¨ æ·±åº¦åˆ†æå®Œæˆæ€»ç»“:")
        print(f"   ğŸ“‹ å¤„ç†æ•°æ®: {results['data_summary']['total_records']:,}æ¡è®°å½•")
        print(f"   ğŸ¯ å”¯ä¸€é…ç½®: {results['data_summary']['unique_configs']}ç§")
        print(f"   ğŸ“Š ç›®æ ‡æŒ‡æ ‡: {results['data_summary']['target_metrics']}ä¸ª")
        print(f"   ğŸ¤– æœ€ä½³æ¨¡å‹RÂ²: {results['analysis_results']['best_model_r2']:.3f}")

        analysis_status = results['analysis_results']
        print(f"\nğŸ” åˆ†ææ¨¡å—çŠ¶æ€:")
        print(f"   âœ… åŸºç¡€åˆ†æ: {'å®Œæˆ' if analysis_status['basic_analysis'] else 'æœªå®Œæˆ'}")
        print(f"   âœ… é«˜çº§åˆ†æ: {'å®Œæˆ' if analysis_status['advanced_analysis'] else 'æœªå®Œæˆ'}")
        print(f"   âœ… åŠ¨æ€åˆ†æ: {'å®Œæˆ' if analysis_status['dynamic_analysis'] else 'æœªå®Œæˆ'}")
        print(f"   âœ… æœºåˆ¶åˆ†æ: {'å®Œæˆ' if analysis_status['mechanism_analysis'] else 'æœªå®Œæˆ'}")

        # è¾“å‡ºæ•°æ®æ¥æºä¿¡æ¯
        if hasattr(analyzer, 'csv_files') and analyzer.csv_files:
            print(f"\nğŸ“‚ æ•°æ®æ¥æº: {len(analyzer.csv_files)}ä¸ªCSVæ–‡ä»¶")
            for i, csv_file in enumerate(analyzer.csv_files[:5]):  # æœ€å¤šæ˜¾ç¤ºå‰5ä¸ª
                print(f"   {i+1}. {Path(csv_file).name}")
            if len(analyzer.csv_files) > 5:
                print(f"   ... è¿˜æœ‰{len(analyzer.csv_files)-5}ä¸ªæ–‡ä»¶")

    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        raise


def analyze_specific_directory(directory_path: str):
    """åˆ†ææŒ‡å®šç›®å½•çš„CSVæ–‡ä»¶"""
    print(f"ğŸ¯ åˆ†ææŒ‡å®šç›®å½•: {directory_path}")

    try:
        # åˆ›å»ºåˆ†æå™¨å®ä¾‹æŒ‡å®šç›®å½•
        analyzer = ExperienceConfigAnalyzer(csv_directory=directory_path)

        # è¿è¡Œæ·±åº¦åˆ†æ
        results = analyzer.run_complete_analysis()

        return results

    except Exception as e:
        print(f"âŒ æŒ‡å®šç›®å½•åˆ†æå¤±è´¥: {str(e)}")
        raise


def analyze_single_file(file_path: str):
    """åˆ†æå•ä¸ªCSVæ–‡ä»¶"""
    print(f"ğŸ“„ åˆ†æå•ä¸ªæ–‡ä»¶: {file_path}")

    try:
        # åˆ›å»ºåˆ†æå™¨å®ä¾‹æŒ‡å®šæ–‡ä»¶
        analyzer = ExperienceConfigAnalyzer(csv_path=file_path)

        # è¿è¡Œæ·±åº¦åˆ†æ
        results = analyzer.run_complete_analysis()

        return results

    except Exception as e:
        print(f"âŒ å•æ–‡ä»¶åˆ†æå¤±è´¥: {str(e)}")
        raise


if __name__ == "__main__":
    main()