#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½“éªŒæ¨¡å¼é…ç½®[1,2,3]å¯¹TileMatchæŒ‡æ ‡å½±å“çš„å…¨é¢åˆ†æå·¥å…·
å•æ–‡ä»¶å®ç°ï¼šæ•°æ®åŠ è½½ã€ç›¸å…³æ€§åˆ†æã€æœºå™¨å­¦ä¹ å»ºæ¨¡ã€å¯è§†åŒ–å±•ç¤º

ä½œè€…: Claude Code Assistant
åˆ›å»ºæ—¶é—´: 2024-09-24
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.preprocessing import StandardScaler
from scipy import stats
from scipy.stats import pearsonr, spearmanr
import warnings
import os
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import json

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
warnings.filterwarnings('ignore')

class ExperienceConfigAnalyzer:
    """ä½“éªŒæ¨¡å¼é…ç½®åˆ†æå™¨ - å•ç±»é›†æˆæ‰€æœ‰åˆ†æåŠŸèƒ½"""

    def __init__(self, csv_path: str = None):
        """åˆå§‹åŒ–åˆ†æå™¨

        Args:
            csv_path: CSVæ•°æ®æ–‡ä»¶è·¯å¾„ï¼Œå¦‚ä¸ºNoneåˆ™è‡ªåŠ¨æ£€æµ‹
        """
        self.csv_path = csv_path or self._find_latest_csv()
        self.data = None
        self.features = None
        self.target_metrics = [
            'DifficultyScore', 'PeakDockCount', 'PressureValueMean',
            'PressureValueMax', 'PressureValueStdDev', 'FinalDifficulty',
            'TotalMoves', 'InitialMinCost', 'DifficultyPosition'
        ]
        self.results = {}

    def _find_latest_csv(self) -> str:
        """è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„BattleAnalysis CSVæ–‡ä»¶"""
        current_dir = Path(__file__).parent
        csv_files = list(current_dir.glob("BattleAnalysis*.csv"))

        if not csv_files:
            # æŸ¥æ‰¾BattleAnalysisResultså­ç›®å½•
            results_dir = current_dir / "BattleAnalysisResults"
            if results_dir.exists():
                csv_files = list(results_dir.glob("BattleAnalysis*.csv"))

        if not csv_files:
            raise FileNotFoundError("æœªæ‰¾åˆ°BattleAnalysis CSVæ–‡ä»¶ï¼Œè¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨")

        # è¿”å›æœ€æ–°çš„æ–‡ä»¶
        latest_file = max(csv_files, key=os.path.getmtime)
        print(f"ğŸ” è‡ªåŠ¨æ£€æµ‹åˆ°CSVæ–‡ä»¶: {latest_file}")
        return str(latest_file)

    def load_and_preprocess(self) -> 'ExperienceConfigAnalyzer':
        """åŠ è½½æ•°æ®å¹¶è¿›è¡Œé¢„å¤„ç†"""
        print("ğŸ“Š åŠ è½½å’Œé¢„å¤„ç†æ•°æ®...")

        # åŠ è½½CSVæ•°æ®
        self.data = pd.read_csv(self.csv_path, encoding='utf-8')
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(self.data)}æ¡è®°å½•")

        # è§£æä½“éªŒæ¨¡å¼é…ç½®
        self._parse_experience_config()

        # ç”Ÿæˆç‰¹å¾å·¥ç¨‹
        self._create_features()

        # æ•°æ®æ¸…æ´—
        self._clean_data()

        print(f"ğŸ“ˆ é¢„å¤„ç†å®Œæˆ: {len(self.data)}æ¡æœ‰æ•ˆè®°å½•, {len(self.features.columns)}ä¸ªç‰¹å¾")
        return self

    def _parse_experience_config(self):
        """è§£æä½“éªŒæ¨¡å¼é…ç½®[1,2,3]æ ¼å¼"""
        def parse_config(config_str):
            """è§£æé…ç½®å­—ç¬¦ä¸²ä¸ºä½ç½®æ•°å€¼"""
            try:
                # ç§»é™¤å¼•å·å’Œæ‹¬å·ï¼Œåˆ†å‰²æ•°å­—
                clean_str = str(config_str).strip('[]"()')
                numbers = [int(x.strip()) for x in clean_str.split(',')]
                return numbers[:3] if len(numbers) >= 3 else [1, 2, 3]  # é»˜è®¤å€¼
            except:
                return [1, 2, 3]  # é”™è¯¯æ—¶è¿”å›é»˜è®¤å€¼

        # è§£æé…ç½®
        configs = self.data['ExperienceMode'].apply(parse_config)

        # æå–ä½ç½®ç‰¹å¾
        self.data['pos1'] = configs.apply(lambda x: x[0])
        self.data['pos2'] = configs.apply(lambda x: x[1])
        self.data['pos3'] = configs.apply(lambda x: x[2])

    def _create_features(self):
        """åˆ›å»ºç‰¹å¾å·¥ç¨‹"""
        # åŸºç¡€ä½ç½®ç‰¹å¾
        features_df = self.data[['pos1', 'pos2', 'pos3']].copy()

        # ç»Ÿè®¡ç‰¹å¾
        features_df['config_mean'] = (self.data['pos1'] + self.data['pos2'] + self.data['pos3']) / 3
        features_df['config_std'] = np.sqrt(((self.data['pos1'] - features_df['config_mean'])**2 +
                                            (self.data['pos2'] - features_df['config_mean'])**2 +
                                            (self.data['pos3'] - features_df['config_mean'])**2) / 3)
        features_df['config_range'] = np.maximum.reduce([self.data['pos1'], self.data['pos2'], self.data['pos3']]) - \
                                     np.minimum.reduce([self.data['pos1'], self.data['pos2'], self.data['pos3']])
        features_df['config_sum'] = self.data['pos1'] + self.data['pos2'] + self.data['pos3']

        # äº¤äº’ç‰¹å¾
        features_df['pos1_pos2'] = self.data['pos1'] * self.data['pos2']
        features_df['pos1_pos3'] = self.data['pos1'] * self.data['pos3']
        features_df['pos2_pos3'] = self.data['pos2'] * self.data['pos3']
        features_df['pos_product'] = self.data['pos1'] * self.data['pos2'] * self.data['pos3']

        # åºåˆ—æ¨¡å¼ç‰¹å¾
        features_df['is_increasing'] = ((self.data['pos1'] <= self.data['pos2']) &
                                      (self.data['pos2'] <= self.data['pos3'])).astype(int)
        features_df['is_decreasing'] = ((self.data['pos1'] >= self.data['pos2']) &
                                      (self.data['pos2'] >= self.data['pos3'])).astype(int)
        features_df['is_uniform'] = ((self.data['pos1'] == self.data['pos2']) &
                                   (self.data['pos2'] == self.data['pos3'])).astype(int)

        # æå€¼ç‰¹å¾
        features_df['has_extreme_low'] = ((self.data['pos1'] == 1) | (self.data['pos2'] == 1) | (self.data['pos3'] == 1)).astype(int)
        features_df['has_extreme_high'] = ((self.data['pos1'] == 9) | (self.data['pos2'] == 9) | (self.data['pos3'] == 9)).astype(int)

        self.features = features_df

    def _clean_data(self):
        """æ•°æ®æ¸…æ´—"""
        # ç§»é™¤GameCompleted=Falseçš„è®°å½•ï¼ˆæ¸¸æˆæœªå®Œæˆï¼‰
        initial_count = len(self.data)
        self.data = self.data[self.data['GameCompleted'] == True].copy()

        # ç§»é™¤ç›®æ ‡æŒ‡æ ‡ä¸ºç©ºå€¼çš„è®°å½•
        for metric in self.target_metrics:
            if metric in self.data.columns:
                self.data = self.data[self.data[metric].notna()].copy()

        # é‡æ–°ç´¢å¼•ç‰¹å¾æ•°æ®
        self.features = self.features.loc[self.data.index].copy()

        print(f"ğŸ§¹ æ•°æ®æ¸…æ´—: {initial_count} -> {len(self.data)}æ¡è®°å½•")

    def correlation_analysis(self) -> Dict:
        """ç›¸å…³æ€§åˆ†æ"""
        print("ğŸ”— æ‰§è¡Œç›¸å…³æ€§åˆ†æ...")

        correlations = {}

        # ä½ç½®ç‰¹å¾ä¸æŒ‡æ ‡çš„ç›¸å…³æ€§
        position_corrs = {}
        for pos in ['pos1', 'pos2', 'pos3']:
            pos_corrs = {}
            for metric in self.target_metrics:
                if metric in self.data.columns:
                    corr, p_value = pearsonr(self.features[pos], self.data[metric])
                    pos_corrs[metric] = {'correlation': corr, 'p_value': p_value, 'significant': p_value < 0.05}
            position_corrs[pos] = pos_corrs

        correlations['position_correlations'] = position_corrs

        # ç‰¹å¾é‡è¦æ€§ï¼ˆåŸºäºæ‰€æœ‰ç‰¹å¾ï¼‰
        feature_importance = {}
        for metric in self.target_metrics:
            if metric in self.data.columns:
                # ä½¿ç”¨éšæœºæ£®æ—è®¡ç®—ç‰¹å¾é‡è¦æ€§
                rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
                rf.fit(self.features, self.data[metric])

                importance_dict = dict(zip(self.features.columns, rf.feature_importances_))
                feature_importance[metric] = dict(sorted(importance_dict.items(),
                                                       key=lambda x: x[1], reverse=True))

        correlations['feature_importance'] = feature_importance

        self.results['correlations'] = correlations
        print("âœ… ç›¸å…³æ€§åˆ†æå®Œæˆ")
        return correlations

    def pattern_analysis(self) -> Dict:
        """é…ç½®æ¨¡å¼åˆ†æ"""
        print("ğŸ¯ æ‰§è¡Œé…ç½®æ¨¡å¼åˆ†æ...")

        patterns = {}

        # åºåˆ—æ¨¡å¼åˆ†æ
        sequence_patterns = {
            'increasing': self.data[self.features['is_increasing'] == 1],
            'decreasing': self.data[self.features['is_decreasing'] == 1],
            'uniform': self.data[self.features['is_uniform'] == 1],
            'mixed': self.data[(self.features['is_increasing'] == 0) &
                             (self.features['is_decreasing'] == 0) &
                             (self.features['is_uniform'] == 0)]
        }

        pattern_stats = {}
        for pattern_name, pattern_data in sequence_patterns.items():
            if len(pattern_data) > 0:
                stats_dict = {}
                for metric in self.target_metrics:
                    if metric in pattern_data.columns:
                        stats_dict[metric] = {
                            'mean': pattern_data[metric].mean(),
                            'std': pattern_data[metric].std(),
                            'count': len(pattern_data)
                        }
                pattern_stats[pattern_name] = stats_dict

        patterns['sequence_patterns'] = pattern_stats

        # æ•°å€¼åˆ†å¸ƒåˆ†æ
        value_analysis = {}
        for pos in ['pos1', 'pos2', 'pos3']:
            pos_analysis = {}
            for value in range(1, 10):
                value_data = self.data[self.features[pos] == value]
                if len(value_data) > 0:
                    value_stats = {}
                    for metric in self.target_metrics:
                        if metric in value_data.columns:
                            value_stats[metric] = {
                                'mean': value_data[metric].mean(),
                                'count': len(value_data)
                            }
                    pos_analysis[f'value_{value}'] = value_stats
            value_analysis[pos] = pos_analysis

        patterns['value_distribution'] = value_analysis

        self.results['patterns'] = patterns
        print("âœ… é…ç½®æ¨¡å¼åˆ†æå®Œæˆ")
        return patterns

    def build_prediction_models(self) -> Dict:
        """æ„å»ºé¢„æµ‹æ¨¡å‹"""
        print("ğŸ¤– æ„å»ºé¢„æµ‹æ¨¡å‹...")

        models = {}

        for metric in self.target_metrics:
            if metric not in self.data.columns:
                continue

            # æ•°æ®å‡†å¤‡
            X = self.features
            y = self.data[metric]

            # æ•°æ®åˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )

            # éšæœºæ£®æ—æ¨¡å‹
            rf = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)
            rf.fit(X_train, y_train)

            # é¢„æµ‹å’Œè¯„ä¼°
            y_pred = rf.predict(X_test)
            r2 = r2_score(y_test, y_pred)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))

            models[metric] = {
                'model': rf,
                'r2_score': r2,
                'rmse': rmse,
                'feature_importance': dict(zip(X.columns, rf.feature_importances_))
            }

        self.results['models'] = models
        print(f"âœ… é¢„æµ‹æ¨¡å‹æ„å»ºå®Œæˆï¼Œå¹³å‡RÂ²: {np.mean([m['r2_score'] for m in models.values()]):.3f}")
        return models

    def create_visualizations(self, output_dir: str = None):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        print("ğŸ“Š åˆ›å»ºå¯è§†åŒ–å›¾è¡¨...")

        if output_dir is None:
            output_dir = Path(self.csv_path).parent / "analysis_charts"

        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)

        # 1. ä½ç½®ç›¸å…³æ€§çƒ­åŠ›å›¾
        self._plot_position_correlation_heatmap(output_path)

        # 2. é…ç½®æ¨¡å¼ç®±çº¿å›¾
        self._plot_pattern_boxplots(output_path)

        # 3. ç‰¹å¾é‡è¦æ€§å›¾
        self._plot_feature_importance(output_path)

        # 4. é…ç½®åˆ†å¸ƒæ•£ç‚¹å›¾
        self._plot_config_distribution(output_path)

        # 5. æ¨¡å‹æ€§èƒ½å›¾
        self._plot_model_performance(output_path)

        print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {output_path}")

    def _plot_position_correlation_heatmap(self, output_path: Path):
        """ç»˜åˆ¶ä½ç½®ç›¸å…³æ€§çƒ­åŠ›å›¾"""
        if 'correlations' not in self.results:
            return

        # å‡†å¤‡æ•°æ®
        pos_corrs = self.results['correlations']['position_correlations']

        corr_matrix = []
        for pos in ['pos1', 'pos2', 'pos3']:
            row = []
            for metric in self.target_metrics:
                if metric in pos_corrs[pos]:
                    row.append(pos_corrs[pos][metric]['correlation'])
                else:
                    row.append(0)
            corr_matrix.append(row)

        corr_df = pd.DataFrame(corr_matrix,
                              index=['ä½ç½®1', 'ä½ç½®2', 'ä½ç½®3'],
                              columns=self.target_metrics)

        # ç»˜å›¾
        plt.figure(figsize=(12, 6))
        sns.heatmap(corr_df, annot=True, cmap='RdBu_r', center=0,
                   fmt='.3f', cbar_kws={'label': 'ç›¸å…³ç³»æ•°'})
        plt.title('ä½“éªŒé…ç½®ä½ç½®ä¸æŒ‡æ ‡ç›¸å…³æ€§çƒ­åŠ›å›¾', fontsize=14, fontweight='bold')
        plt.xlabel('æ€§èƒ½æŒ‡æ ‡')
        plt.ylabel('é…ç½®ä½ç½®')
        plt.tight_layout()
        plt.savefig(output_path / 'position_correlation_heatmap.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_pattern_boxplots(self, output_path: Path):
        """ç»˜åˆ¶é…ç½®æ¨¡å¼ç®±çº¿å›¾"""
        if 'patterns' not in self.results:
            return

        # ä¸ºå…³é”®æŒ‡æ ‡åˆ›å»ºç®±çº¿å›¾
        key_metrics = ['DifficultyScore', 'PeakDockCount', 'PressureValueMean']

        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        axes = axes.flatten()

        # åºåˆ—æ¨¡å¼å¯¹æ¯”
        pattern_data = []
        for pattern in ['increasing', 'decreasing', 'uniform', 'mixed']:
            mask = getattr(self.features, f'is_{pattern}', None)
            if pattern == 'mixed':
                mask = ((self.features['is_increasing'] == 0) &
                       (self.features['is_decreasing'] == 0) &
                       (self.features['is_uniform'] == 0))
            else:
                mask = self.features[f'is_{pattern}'] == 1

            if mask.any():
                pattern_subset = self.data[mask].copy()
                pattern_subset['pattern'] = pattern
                pattern_data.append(pattern_subset)

        if pattern_data:
            combined_data = pd.concat(pattern_data, ignore_index=True)

            for i, metric in enumerate(key_metrics[:3]):
                if metric in combined_data.columns:
                    sns.boxplot(data=combined_data, x='pattern', y=metric, ax=axes[i])
                    axes[i].set_title(f'{metric} - åºåˆ—æ¨¡å¼å¯¹æ¯”')
                    axes[i].tick_params(axis='x', rotation=45)

        # ä½ç½®æ•°å€¼åˆ†å¸ƒ
        position_data = []
        for pos in ['pos1', 'pos2', 'pos3']:
            pos_subset = self.data.copy()
            pos_subset['position'] = pos
            pos_subset['value'] = self.features[pos]
            position_data.append(pos_subset)

        if position_data:
            pos_combined = pd.concat(position_data, ignore_index=True)
            sns.boxplot(data=pos_combined, x='value', y='DifficultyScore',
                       hue='position', ax=axes[3])
            axes[3].set_title('DifficultyScore - ä½ç½®æ•°å€¼åˆ†å¸ƒ')
            axes[3].legend(title='ä½ç½®')

        plt.suptitle('ä½“éªŒé…ç½®æ¨¡å¼åˆ†æ', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(output_path / 'pattern_boxplots.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_feature_importance(self, output_path: Path):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾"""
        if 'models' not in self.results:
            return

        # é€‰æ‹©å‰3ä¸ªé‡è¦æŒ‡æ ‡
        key_metrics = ['DifficultyScore', 'PeakDockCount', 'PressureValueMean']

        fig, axes = plt.subplots(1, 3, figsize=(18, 6))

        for i, metric in enumerate(key_metrics):
            if metric in self.results['models']:
                importance = self.results['models'][metric]['feature_importance']

                # å–å‰8ä¸ªé‡è¦ç‰¹å¾
                top_features = dict(sorted(importance.items(), key=lambda x: x[1], reverse=True)[:8])

                features = list(top_features.keys())
                values = list(top_features.values())

                bars = axes[i].barh(features, values)
                axes[i].set_title(f'{metric}\nç‰¹å¾é‡è¦æ€§ (RÂ²={self.results["models"][metric]["r2_score"]:.3f})')
                axes[i].set_xlabel('é‡è¦æ€§åˆ†æ•°')

                # é¢œè‰²æ˜ å°„
                colors = plt.cm.viridis(np.linspace(0, 1, len(values)))
                for bar, color in zip(bars, colors):
                    bar.set_color(color)

        plt.suptitle('æœºå™¨å­¦ä¹ æ¨¡å‹ç‰¹å¾é‡è¦æ€§åˆ†æ', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(output_path / 'feature_importance.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_config_distribution(self, output_path: Path):
        """ç»˜åˆ¶é…ç½®åˆ†å¸ƒæ•£ç‚¹å›¾"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))

        # 3Dé…ç½®ç©ºé—´æŠ•å½± (pos1 vs pos2ï¼Œé¢œè‰²è¡¨ç¤ºpos3)
        scatter = axes[0,0].scatter(self.features['pos1'], self.features['pos2'],
                                  c=self.features['pos3'], cmap='viridis', alpha=0.6)
        axes[0,0].set_xlabel('ä½ç½®1æ•°å€¼')
        axes[0,0].set_ylabel('ä½ç½®2æ•°å€¼')
        axes[0,0].set_title('é…ç½®ç©ºé—´åˆ†å¸ƒ (é¢œè‰²=ä½ç½®3)')
        plt.colorbar(scatter, ax=axes[0,0], label='ä½ç½®3æ•°å€¼')

        # DifficultyScoreåˆ†å¸ƒ
        if 'DifficultyScore' in self.data.columns:
            scatter2 = axes[0,1].scatter(self.features['config_mean'], self.features['config_std'],
                                       c=self.data['DifficultyScore'], cmap='coolwarm', alpha=0.6)
            axes[0,1].set_xlabel('é…ç½®å‡å€¼')
            axes[0,1].set_ylabel('é…ç½®æ ‡å‡†å·®')
            axes[0,1].set_title('éš¾åº¦åˆ†æ•°åˆ†å¸ƒ')
            plt.colorbar(scatter2, ax=axes[0,1], label='DifficultyScore')

        # åºåˆ—æ¨¡å¼åˆ†å¸ƒ
        pattern_colors = {'increasing': 'red', 'decreasing': 'blue', 'uniform': 'green', 'mixed': 'gray'}
        for pattern, color in pattern_colors.items():
            if pattern == 'mixed':
                mask = ((self.features['is_increasing'] == 0) &
                       (self.features['is_decreasing'] == 0) &
                       (self.features['is_uniform'] == 0))
            else:
                mask = self.features[f'is_{pattern}'] == 1

            if mask.any():
                axes[1,0].scatter(self.features[mask]['pos1'], self.features[mask]['pos3'],
                                alpha=0.6, c=color, label=pattern, s=20)

        axes[1,0].set_xlabel('ä½ç½®1æ•°å€¼')
        axes[1,0].set_ylabel('ä½ç½®3æ•°å€¼')
        axes[1,0].set_title('åºåˆ—æ¨¡å¼åˆ†å¸ƒ')
        axes[1,0].legend()

        # æå€¼ç»„åˆåˆ†æ
        extreme_mask = (self.features['has_extreme_low'] == 1) | (self.features['has_extreme_high'] == 1)
        normal_mask = ~extreme_mask

        if 'PeakDockCount' in self.data.columns:
            axes[1,1].scatter(self.data[normal_mask]['PeakDockCount'],
                            self.data[normal_mask]['DifficultyScore'] if 'DifficultyScore' in self.data.columns else 0,
                            alpha=0.5, c='blue', label='å¸¸è§„é…ç½®', s=20)
            axes[1,1].scatter(self.data[extreme_mask]['PeakDockCount'],
                            self.data[extreme_mask]['DifficultyScore'] if 'DifficultyScore' in self.data.columns else 0,
                            alpha=0.7, c='red', label='æå€¼é…ç½®', s=20)
            axes[1,1].set_xlabel('PeakDockCount')
            axes[1,1].set_ylabel('DifficultyScore')
            axes[1,1].set_title('æå€¼é…ç½®æ•ˆåº”åˆ†æ')
            axes[1,1].legend()

        plt.suptitle('ä½“éªŒé…ç½®åˆ†å¸ƒç‰¹å¾åˆ†æ', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(output_path / 'config_distribution.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_model_performance(self, output_path: Path):
        """ç»˜åˆ¶æ¨¡å‹æ€§èƒ½å›¾"""
        if 'models' not in self.results:
            return

        metrics = list(self.results['models'].keys())
        r2_scores = [self.results['models'][m]['r2_score'] for m in metrics]
        rmse_scores = [self.results['models'][m]['rmse'] for m in metrics]

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

        # RÂ²åˆ†æ•°
        bars1 = ax1.bar(metrics, r2_scores, color='skyblue', alpha=0.7)
        ax1.set_title('é¢„æµ‹æ¨¡å‹RÂ²æ€§èƒ½è¯„åˆ†')
        ax1.set_ylabel('RÂ²åˆ†æ•°')
        ax1.tick_params(axis='x', rotation=45)
        ax1.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='åŸºå‡†çº¿(0.5)')
        ax1.legend()

        # ä¸ºæ¯ä¸ªbaræ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, score in zip(bars1, r2_scores):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{score:.3f}', ha='center', va='bottom')

        # RMSEåˆ†æ•° (æ ‡å‡†åŒ–æ˜¾ç¤º)
        bars2 = ax2.bar(metrics, rmse_scores, color='lightcoral', alpha=0.7)
        ax2.set_title('é¢„æµ‹æ¨¡å‹RMSEè¯¯å·®')
        ax2.set_ylabel('RMSE')
        ax2.tick_params(axis='x', rotation=45)

        plt.suptitle('æœºå™¨å­¦ä¹ æ¨¡å‹æ€§èƒ½è¯„ä¼°', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(output_path / 'model_performance.png', dpi=300, bbox_inches='tight')
        plt.close()

    def generate_report(self, output_path: str = None) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("ğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")

        if output_path is None:
            output_path = Path(self.csv_path).parent / "analysis_report.md"

        report = []
        report.append("# ä½“éªŒæ¨¡å¼é…ç½®[1,2,3]åˆ†ææŠ¥å‘Š\n")
        report.append(f"**æ•°æ®æº**: {self.csv_path}")
        report.append(f"**åˆ†ææ—¶é—´**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"**æ ·æœ¬æ•°é‡**: {len(self.data):,}æ¡\n")

        # æ•°æ®æ¦‚è§ˆ
        report.append("## ğŸ“Š æ•°æ®æ¦‚è§ˆ\n")
        report.append(f"- é…ç½®èŒƒå›´: pos1=[{self.features['pos1'].min()}-{self.features['pos1'].max()}], " +
                     f"pos2=[{self.features['pos2'].min()}-{self.features['pos2'].max()}], " +
                     f"pos3=[{self.features['pos3'].min()}-{self.features['pos3'].max()}]")
        report.append(f"- å”¯ä¸€é…ç½®æ•°: {len(self.data[['pos1', 'pos2', 'pos3']].drop_duplicates())}ç§")

        # ç›¸å…³æ€§åˆ†æç»“æœ
        if 'correlations' in self.results:
            report.append("\n## ğŸ”— ç›¸å…³æ€§åˆ†æç»“æœ\n")

            # ä½ç½®é‡è¦æ€§æ’åº
            pos_importance = {}
            for pos in ['pos1', 'pos2', 'pos3']:
                avg_abs_corr = np.mean([abs(self.results['correlations']['position_correlations'][pos][m]['correlation'])
                                      for m in self.target_metrics
                                      if m in self.results['correlations']['position_correlations'][pos]])
                pos_importance[pos] = avg_abs_corr

            sorted_positions = sorted(pos_importance.items(), key=lambda x: x[1], reverse=True)

            report.append("### ä½ç½®é‡è¦æ€§æ’åº:")
            for i, (pos, importance) in enumerate(sorted_positions, 1):
                pos_name = f"ä½ç½®{pos[-1]}"
                report.append(f"{i}. **{pos_name}**: {importance:.3f} (å¹³å‡ç»å¯¹ç›¸å…³ç³»æ•°)")

        # æ¨¡å¼åˆ†æç»“æœ
        if 'patterns' in self.results:
            report.append("\n## ğŸ¯ é…ç½®æ¨¡å¼åˆ†æ\n")

            # åºåˆ—æ¨¡å¼ç»Ÿè®¡
            seq_patterns = self.results['patterns']['sequence_patterns']
            if seq_patterns:
                report.append("### åºåˆ—æ¨¡å¼åˆ†å¸ƒ:")
                for pattern, stats in seq_patterns.items():
                    count = stats.get('DifficultyScore', {}).get('count', 0)
                    if count > 0:
                        avg_difficulty = stats.get('DifficultyScore', {}).get('mean', 0)
                        pattern_name = {'increasing': 'é€’å¢', 'decreasing': 'é€’å‡',
                                      'uniform': 'ç›¸ç­‰', 'mixed': 'æ··åˆ'}[pattern]
                        report.append(f"- **{pattern_name}æ¨¡å¼**: {count}ä¸ªæ ·æœ¬, å¹³å‡éš¾åº¦: {avg_difficulty:.2f}")

        # æ¨¡å‹é¢„æµ‹ç»“æœ
        if 'models' in self.results:
            report.append("\n## ğŸ¤– é¢„æµ‹æ¨¡å‹æ€§èƒ½\n")

            model_performance = [(metric, model['r2_score']) for metric, model in self.results['models'].items()]
            model_performance.sort(key=lambda x: x[1], reverse=True)

            report.append("### æ¨¡å‹RÂ²æ€§èƒ½æ’åº:")
            for i, (metric, r2) in enumerate(model_performance, 1):
                performance_level = "ä¼˜ç§€" if r2 > 0.7 else "è‰¯å¥½" if r2 > 0.5 else "ä¸€èˆ¬" if r2 > 0.3 else "è¾ƒå·®"
                report.append(f"{i}. **{metric}**: RÂ²={r2:.3f} ({performance_level})")

        # å…³é”®å‘ç°
        report.append("\n## ğŸ’¡ å…³é”®å‘ç°\n")
        report.append("### ä¸»è¦ç»“è®º:")

        # åŸºäºåˆ†æç»“æœç”Ÿæˆç»“è®º
        if 'correlations' in self.results and 'models' in self.results:
            # æ‰¾å‡ºé¢„æµ‹æ€§èƒ½æœ€å¥½çš„æŒ‡æ ‡
            best_metric = max(self.results['models'].items(), key=lambda x: x[1]['r2_score'])
            report.append(f"1. **{best_metric[0]}** æ˜¯æœ€å¯é¢„æµ‹çš„æŒ‡æ ‡ (RÂ²={best_metric[1]['r2_score']:.3f})")

            # æ‰¾å‡ºæœ€é‡è¦çš„ä½ç½®
            most_important_pos = sorted_positions[0][0] if 'sorted_positions' in locals() else 'pos1'
            report.append(f"2. **{most_important_pos}** å¯¹æ•´ä½“æ€§èƒ½å½±å“æœ€å¤§")

            report.append(f"3. å…±è¯†åˆ«å‡º {len(self.features.columns)} ä¸ªæœ‰æ•ˆç‰¹å¾ç»´åº¦")

        report.append("\n### ä¼˜åŒ–å»ºè®®:")
        report.append("1. é‡ç‚¹å…³æ³¨å½±å“åŠ›æœ€å¤§çš„ä½ç½®é…ç½®")
        report.append("2. è€ƒè™‘åºåˆ—æ¨¡å¼å¯¹æ€§èƒ½çš„ç³»ç»Ÿæ€§å½±å“")
        report.append("3. é¿å…æå€¼é…ç½®å¯èƒ½å¸¦æ¥çš„ä¸ç¨³å®šæ€§")

        # å†™å…¥æ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))

        print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        return str(output_path)

    def run_complete_analysis(self, output_dir: str = None) -> Dict:
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print("ğŸš€ å¼€å§‹å®Œæ•´ä½“éªŒé…ç½®åˆ†æ...")

        # æ‰§è¡Œæ‰€æœ‰åˆ†ææ­¥éª¤
        self.load_and_preprocess()
        correlations = self.correlation_analysis()
        patterns = self.pattern_analysis()
        models = self.build_prediction_models()

        # åˆ›å»ºå¯è§†åŒ–
        self.create_visualizations(output_dir)

        # ç”ŸæˆæŠ¥å‘Š
        report_path = self.generate_report()

        # æ±‡æ€»ç»“æœ
        summary = {
            'data_summary': {
                'total_records': len(self.data),
                'unique_configs': len(self.data[['pos1', 'pos2', 'pos3']].drop_duplicates()),
                'target_metrics': len(self.target_metrics)
            },
            'analysis_results': {
                'correlations_completed': len(correlations) > 0,
                'patterns_completed': len(patterns) > 0,
                'models_completed': len(models) > 0,
                'best_model_r2': max([m['r2_score'] for m in models.values()]) if models else 0
            },
            'output_files': {
                'report_path': report_path,
                'charts_directory': output_dir or Path(self.csv_path).parent / "analysis_charts"
            }
        }

        print("ğŸ‰ å®Œæ•´åˆ†ææµç¨‹æ‰§è¡Œå®Œæˆ!")
        print(f"ğŸ“„ æŠ¥å‘Šè·¯å¾„: {summary['output_files']['report_path']}")
        print(f"ğŸ“Š å›¾è¡¨ç›®å½•: {summary['output_files']['charts_directory']}")

        return summary


def main():
    """ä¸»å‡½æ•° - ç¤ºä¾‹ä½¿ç”¨"""
    print("ğŸ”¬ ä½“éªŒæ¨¡å¼é…ç½®åˆ†æå·¥å…·å¯åŠ¨...")

    try:
        # åˆ›å»ºåˆ†æå™¨å®ä¾‹
        analyzer = ExperienceConfigAnalyzer()

        # è¿è¡Œå®Œæ•´åˆ†æ
        results = analyzer.run_complete_analysis()

        print(f"\nâœ¨ åˆ†æå®Œæˆæ€»ç»“:")
        print(f"   ğŸ“ å¤„ç†æ•°æ®: {results['data_summary']['total_records']:,}æ¡è®°å½•")
        print(f"   ğŸ¯ å”¯ä¸€é…ç½®: {results['data_summary']['unique_configs']}ç§")
        print(f"   ğŸ“Š ç›®æ ‡æŒ‡æ ‡: {results['data_summary']['target_metrics']}ä¸ª")
        print(f"   ğŸ¤– æœ€ä½³æ¨¡å‹RÂ²: {results['analysis_results']['best_model_r2']:.3f}")

    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")
        raise


if __name__ == "__main__":
    main()